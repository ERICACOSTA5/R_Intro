[
["index.html", "Aplicaciones de R en Agronomía Motivación", " Aplicaciones de R en Agronomía Motivación “Una de las cosas más importantes que puedes hacer es dedicar un tiempo para aprender un lenguaje de programación. Aprender a programar es como aprender otro idioma: requiere tiempo y entrenamiento, y no hay resultados prácticos inmediatos. Pero si superas esa primera subida empinada de la curva de aprendizaje, las ganancias como científico son enormes. Programar no sólo te liberará de la camisa de fuerza de los softwares estadísticos cerrados, sino que también agudizará tus habilidades analíticas y ampliará los horizontes de modelado ecológico y estadístico.” ~ Adaptación de (Ellison and Gotelli 2004) ~ Podríamos resumir nuestro trabajo como científicos, desde la recolección de datos en el campo, hasta su divulgación a través del siguiente esquema: ~ Adaptación de “R for Data Science” (Wickham and Grolemund 2016) ~ Objetivos El curso pretende proveer herramientas de programación básicas para llevar adelante el proceso de investigación tomando como base el esquema de trabajo anterior. Para ello, usaremos datos (reales o simulados) típicos del área de Ciencias Agrarias. Importante: i) no es un curso de estadística; ii) entendemos la programación como un simple medio para optimizar nuestra labor cotidiana (no como un fin mismo), al final del día seguiremos siendo fitopatólogos, fisiólogos, bioquímicos, etc.; iii) maximizaremos la adopción de la filosofia tidyverse; y iv) obtendrán mayor provecho aquellas personas que se inician en R, ya que los contenidos pretenden ser de baja complejidad, posibilitando profundizar el conocimiento por los propios medios del alumno. Por qué R? (R Core Team 2017) 1 Software libre - multiplataforma 2 Aprender un lenguaje de programación: ejercicio mental/lógica (Aprender estadística resulta mucho mas ameno) 3 Software actualizado y con una amplia gama de paquetes específicos (drc, agricolae, epiphy…) 4 Gran flexibilidad y elegancia de los gráficos 5 Popularidad - Comunidad activa y creciente dispuesta a ayudar (aprendemos a usar terminos técnicos de ciencia de datos en inglés) 6 Programar ya no es solo computación (CV/relevant skills) Autor Juan Pablo Edwards Molina: Investigador - Fitopatología (INTA Balcarce). Email: edwardsmolina@gmail.com Google scholar Twitter: juanchiem GitHub: https://github.com/juanchiem Este obra está licenciado com uma Licença Creative Commons Atribuição-NãoComercial-SemDerivações 4.0 Internacional. References "],
["config.html", "1 Configuraciones básicas", " 1 Configuraciones básicas Instalación de programas 1° R 2° R Studio (bajar la versión Free) RStudio es un entorno de desarrollo integrado (IDE) para el lenguaje de programación R, o sea es la interface por medio de la cual se ejecutan acciones en R. Configuraciones iniciales (sugeridas). Dirigirse a la sección “Tools/Global options” "],
["paquetes-de-r.html", "Paquetes de R", " Paquetes de R Un paquete es una colección de funciones, datos y código R que se almacenan en una carpeta conforme a una estructura bien definida, fácilmente accesible para R. Hay paquetes oficiales (disponibles en CRAN) y no oficiales (disponibles a través de plataformas como github). A la fecha (febrero de 2019) hay 13753 paquetes oficiales. La simple instalación de R trae consigo múltiples paquetes que permiten un funcionamiento básico de importación de datos, ajuste y evaluación de modelos estadísticos y representaciones gráficas. Sin embargo, la enorme potencia de R deriva de su capacidad de incorporar nuevas funciones generadas por su gran comunidad de usuarios (ver novedades en: r weekly; r-bloggers; revolution analytics; RStudio blog) En la web de R se puede consultar la lista de paquetes disponibles, y en la sección Task Views se puede consultar los mismos ordenados por áreas de aplicación. Existen varias vias de instalación de paquetes: Via CRAN (Comprehensive R Archive Network): install.packages(\"nombre_del_paquete\") O simplemente en el panel de paquetes. Paquetes no oficiales via Github: devtools::install_github(\"rstudio/epiphy\") Una vez instalado, hay que cargar los paquetes que contienen las funciones que vayamos a usar en cada sesión library(nombre-del-paquete) "],
["workflow-componentes.html", "Workflow componentes", " Workflow componentes Varios tipos de archivos serán creados y usados durante una sesión de R: datos crudos (hojas de cálculo) - datos manipulados scripts gráficos reportes de resultados Una sesión de análisis debe poder ser retomada en cualquier momento pudiendo darse por concluída cuando el trabajo es publicado. Hasta entonces debemos tener rápido acceso a todos los objetos creados en sesiones anteriores. Para ello debemos manejarnos siempre bajo buenas prácticas de trabajo. Esto nos permitirá entender que quisimos hacer tiempo atrás, seremos intuitivos para encontrar archivos/objetos, y finalmente crearemos trabajos reproducibles… Una forma práctica de administrar todos los objetos que una sesión es crear un proyecto de R para cada sesión. Una sugerencia es generar subcarpetas en nuestras máquinas, en preferencia dentro de dropbox / google drive. Esto no solo mantendrá nuestro trabajo resguardado de posibles pérdidas (backup), retomarlo desde diferentes maquinas (trabajo/casa), sino que también le permitirá compartir en tiempo real sus avances con los colaboradores de su trabajo. Crear una carpeta Intro_R en sus máquinas Crear una nuevo proyecto “Intro_R.Rproj” Crear un script “1_intro” Donde se guardaria el siguiente gráfico? plot(pressure) "],
["s-o-s-.html", "S.O.S.", " S.O.S. En el mismo R: ?auc; ??auc; F1 sobre la función Googlear: “r generate a sequence of uppercase letters” Stack Overflow: foros de pregunta y respuesta ampliamente utilizados por todos los lenguajes de programación. En algunos paises, llegan hasta a usar la reputación de los usuarios como diferencial en el currículum! ¿Cómo hacer una buena pregunta en el stack overflow? Ser consciso pero gentil… Ser reproducible: su código debe correr en cualquier maquina. La comunidad no irá a ayudarle si no pueden reproducir su error (detallar paquetes y version de R en caso necesario) library(reprex). "],
["sintaxis-basica.html", "2 Sintaxis básica", " 2 Sintaxis básica La sintaxis en R es muy similar a la de otros lenguajes de programación como JAVA o C. Las normas básicas que definen la sintaxis de R son: No se tienen en cuenta los espacios en blancos: podemos o no dejar espacios para que el código se puede ordenar de forma adecuada y poder entenderse. Se distinguen las mayúsculas y minúsculas: para variables en el código, podemos crear diferentes variables con nombres iguales pero alternando mayúsculas y minúsculas. Se pueden incluir comentarios: como vimos anteriormente los comentarios se utilizan para añadir información en el código. No es necesario terminar cada sentencia con el carácter de punto y coma (;): en la mayoría de lenguajes de programación, es obligatorio terminar cada sentencia con este carácter. En en cambio R podemos o no terminar de esta forma. "],
["calc.html", "2.1 R calculadora", " 2.1 R calculadora Ver tablas resumen de operadores aritméticos y lógicos (al final del capítulo) 4 + 9 4 - 3 * 1 # 4%1 4&gt;3 4 == 3 4 == 4 (4 + 5 ) * 7 - (36/18)^3 (Recordando de la primaria el orden de las operaciones: paréntesis &lt; exponentes (potencia o raiz) &lt; productos/división &lt; suma/resta) Ej 1: Está bien la siguiente expresión? 5 + 3 * 10 %/% 3 == 15 Agregue parentesis para que la expresión de un resultado contrario. Rendimiento de trigo en función de la severidad de fusariosis de la espiga (Madden and Paul 2009) El intercepto de la regresión lineal estimada (rendimiento de trigo libre de enfermedad) fue de 4.10 t/ha, y la pendiente fue de 0.038 t/ha por unidad de aumento de la severidad de la enfermedad. El tipo de trigo tuvo efecto significativo en el intercepto pero no en la pendiente: trigo de invierno tuvo, en promedio, 0.85 t/ha mas rendimiento que el trigo de primavera. Ej 2: Cuanto seria el rendimiento de ambas variedades de trigo con 1, 10 o 20% de severidad de la enfermedad? Algunos cálculos sqrt(3) # 3^0.5 2^(1/3) # ^(1/n) log(10) log(10, base=10) round(4.3478, digits=3) # ceiling(4.3478) floor(4.3478) (Note que R está en inglés (decimales “.”, nombre de las funciones) y es “case sensitive”!!) # Ej 1: 5 + (3 * 10) %/% 3 == 15 # Ej 2: 4.1 - 0.038 * 10; (1-(3.72/4.1))*100 References "],
["funciones.html", "2.2 Funciones", " 2.2 Funciones Una función es un conjunto de sentencias organizadas conjuntamente para realizar una tarea específica. Los paquetes son basicamente un set de funciones generadas por los autores de los mismos pero el usuario puede crear sus propias funciones. La sintaxis básica de una función de R es la siguiente nombre_funcion &lt;- function(arg_1, arg_2, ...) { cuerpo_de_la_función output # return() } Las diferentes partes de una función son: Nombre de la función: este es el nombre real de la función. Se almacena en el entorno R como un objeto con este nombre. Generalmente, el nombre es intuitivo, por ejemplo, mean es la función que calcula la media, round es la funión que redondea un número. Argumentos - Un argumento es un marcador de posición. Cuando se invoca una función, se pasa un valor al argumento. Los argumentos son opcionales; es decir, una función puede no contener argumentos. También los argumentos pueden tener valores por defecto. Cuerpo de la función: el cuerpo de la función contiene una colección de sentencias que definen lo que hace la función. Valor de retorno: el valor de retorno de una función es la última expresión en el cuerpo de la función que se va a evaluar. numb &lt;- 1:6 round(mean(numb)) # floor() # ceiling() trunc() Si es necesario, el usuario puede generar sus propias funciones. Un clásico ejemplo de la utilidad de estas funciones “user-defined” es la preparación de soluciones partiendo de un stock o fuente a diluir, usando la equivalencia: \\[c1 * v1 = c2 * v2\\] Obviamente tanto \\(c1;c2\\), como \\(v1;v2\\), están en las mismas unidades. Para nuestra comodidad \\(c=\\%\\) y \\(v=ml\\). Nos indican que preparemos 500 ml de una solución desinfectante de NaOCl al 5%, partiendo de una lavandina concentrada (55 g Cl/L). La pregunta que del millón es: qué volumen de lavandina preciso? Por lo tanto debemos despejar V1 de la equivalencia, o sea, sería nuestro output de nuestra función. Empecemos los cálculos: Si el NaOCl tiene un peso molecular de 74.5 g y el Cl pesa 35.5 g, este representa el 47.6% de la molécula de NaOCl. Por lo tanto podemos decir que la lavandina comercial posee x NaOCl = Cl/0.476 en 1 L, o bien x NaOCl % = x NaoCl/10 Si deseamos preparar 500 ml de NaOCl al 5% para la desinfección (2.5% de Cl activo, aprox.) debemos obtener: \\[v1 = (c2*v2)/c1\\] vol_lavandina &lt;- function(c1, c2, v2){ c1 &lt;- (c1/0.476)/10 # pasar g/L a % c2 &lt;- c2 # concentración que me pide el protocolo (%) v2 &lt;- v2 # volumen de la solución que deseo (ml) v1 &lt;- (c2*v2)/c1 # aliquota que debo usar return(paste(&quot;Coloque&quot;, round(v1,1), &quot;ml de lavandina y enrase con agua hasta completar&quot;, v2, &quot;ml&quot;)) } vol_lavandina(55, # g cloro / L (Lavandina) 5, # % ClONa deseada 500) # ml de la solución deseada ## [1] &quot;Coloque 216.4 ml de lavandina y enrase con agua hasta completar 500 ml&quot; Al reportar los resultados de los test de comparaciones de medias obtenidas luego del análisis de varianza es interesante agregar en los párrafos de los resultados cuánto incremento o se redujo un tratamiento en referencia a un testigo en términos porcentuales. Genere una función que permita realizar estos cálculos. Tome como ayuda este link para cotejar sus resultados. perc_change &lt;- function(v1, v2) { pc &lt;- (v2-v1)/v1 *100 return(paste(round(digits=1, pc), &quot;%&quot;)) } perc_change(1, 1.5) perc_change(0.5, 1) perc_change(80, 90) perc_change(90, 80) Claro que en la inmensa comunidad de usuario de R, ya hubo alguien que incluyó esa función en un paquete… #percentua relative differences quantmod::Delt(80,90)*100 80+(80*0.125) quantmod::Delt(90,80)*100 90+(-90*0.1111111) "],
["tablas-resumen.html", "2.3 Tablas resumen", " 2.3 Tablas resumen Table 2.1: Operadores aritméticos Operador Detalle x + y Suma de x e y x - y Resta de x menos y x * y Multiplicación x / y División de x por y x %/% y Parte entera de la división de x por y x %% y Resto de la división de x por y x ^ y x elevado a y-ésima potencia (equivalente a **) Table 2.2: Operadores lógicos Operador Prueba.lógica x &lt; y x menor que y? x &lt;= y x menor o igual que y? x &gt; y x mayor que y? x &gt;= y x mayor o igual que y? x == y x igual que y? x != y x diferente que y? Table 2.3: Funciones matemáticas Operador Detalle sqrt(x) raiz de x exp(y) exponencial de y log(x) logaritmo natural de x = ln log10(x) Logaritmo base 10 de x sum(x) suma todos los elementos de x prod(x) producto de todos los elementos de x round(x, n) redondea x a n-digitos Table 2.4: Algunos atajos comúnentes usados Teclas Detalle Alt+Shift+K panel de todos los atajos Ctrl+Z / Ctrl+Shift+Z undo/redo Alt+ - &lt;- Ctrl+r corre la linea/bloque completa de codigo Ctrl+l limpia la consola Ctrl+Shift+c silencia la linea Ctrl+i indexa el bloque de código "],
["data-type.html", "3 Datos: tipos y estructuras", " 3 Datos: tipos y estructuras En términos genéricos, todos los elementos que maneja R son objetos: un valor numérico es un objeto, un vector es un objeto, una función es un objeto, una base de datos es un objeto, un gráfico es un objeto… Para realizar un uso eficiente de R es preciso entender y aprender a manipular bien las distintas clases de objetos que maneja el programa. En esta sección nos vamos a ocupar particulamente de aquellos objetos que R utiliza para representar datos: valores, vectores, matrices, dataframes y listas. "],
["tipos-de-datos.html", "3.1 Tipos de datos", " 3.1 Tipos de datos La unidad básica de datos en R es un vector, los cuales pueden ser de diferentes clases. Los que más usaremos son las siguientes cuatro clases. Clase Ejemplo numeric c(12.3, 5, 999) logical c(TRUE, FALSE) integer c(2L, 34L, 0L) character c(‘a’, ‘good’, ‘TRUE’, ‘23.4’) 3.1.1 Vectores # concatenación de elementos atómicos v &lt;- c(8, 7, 9, 10, 10, 111) class(v) (b &lt;- c(&quot;A&quot;, &quot;b&quot;)) class(b) is.character(b) is.numeric(b) (m &lt;- c(TRUE, FALSE, T, F)) ; class(m) # Propiedades de v # ?length length(v) summary(v) #v &lt;- edit(v) sort(v) Operaciones con vectores v - 1 # Medidas de posición mean(v) median(v) # Medidas de dispersión var(v) sd(v) sqrt(var(v)) IQR(v) range(v) quantile(v, 0.1) ecdf(v)(7) max(v) min(v) sum(v) Cree tres nuevos vectores que sean: i) la potencia cuadrada de 3.5 de v; ii) la raiz cubica de v; iii) el logaritmo natural de la diferencia de i) y ii) Secuencia 1:7 seq(from = 0, to = 20, #by=2) # length=4) rep(1:3, times=3) # , each=3 3.1.2 Números aleatorios La generación de números aleatorios es en muchas ocasiones un requerimiento esencial en investigación científica. Proceder de este modo puede reducir cualquier sesgo generado por nuestra persona a la hora de seleccionar una muestra, o aplicar un tratamiento a una unidad experimental. Generar números enteros de modo aleatorio de una muestra determinada sample() sample(1:30, size=10, replace=F) #sin reposición Generar numeros aleatorios de una distribución especifica de parámetros conocidos: runif() - números racionales aleatoriamente, uniformemente distribuidos en un intervalo num_unif &lt;- runif(100, min=3, max=4) hist(num_unif) rnorm() - números aleatorios, pertenecientes a una población con distribución normal, con parámetros μ y σ. num_norm &lt;- rnorm(100, mean=70, sd=5) hist(num_norm) Vamos a recrear estas muestras partiendo de la información contenida en la tabla (Parra-Bracamonte et al. 2007) set.seed(123) PesoNac &lt;- rnorm(23570, mean=32.2, sd=1.8) range(PesoNac) hist(PesoNac) hist(PesoNac, prob=TRUE) Propiedades de vectores Si colocaramos dos o mas clases diferentes dentro de un mismo vector, R va forzar a que todos los elementos pasen a pertenecer a una misma clase. El número 1.7 cambiaria a “1.7” se fuera creado junto con “a”. y &lt;- c(1.7, &quot;a&quot;) ## character y &lt;- c(TRUE, 2) ## numeric y &lt;- c(TRUE, &quot;a&quot;) ## character Forzando las clases explicitamente as.character(), as.numeric(), as.integer() y as.logical() Factores Conceptualmente, en R, los factores son variables categóricas con un número finito de valores o niveles (levels). Son variables clasificadoras o agrupadoras de los nuestros datos. Uno de los usos más importantes de los factores es en el modelado estadístico, dado que estos son considerados de manera diferente a las variables continuas. Claro ejemplo de factores son los tratamientos, por ej: fungicidas, genotipos, bloques, etc. Los niveles de un factor puede estar codificados como valores numéricos o como caracteres (labels). Independientemente de que el factor sea numérico o carácter, sus valores son siempre almacenados internamente por R como números enteros, con lo que se consigue economizar memoria. Podemos comprobar que la ordenación de los niveles es simplemente alfabética. clones = c(&quot;control&quot;, &quot;B35&quot;, &quot;A12&quot;, &quot;T99&quot;, &quot;control&quot;, &quot;A12&quot;, &quot;B35&quot;, &quot;T99&quot;, &quot;control&quot;, &quot;A12&quot;, &quot;B35&quot;, &quot;T99&quot;, &quot;control&quot;) class(clones) levels(clones) clones_f = factor(clones) levels(clones_f) table(clones_f) En general deseamos algun orden especifico de nuestros niveles del factor, por ej: clones_f_ord &lt;- factor(clones_f, levels=c(&quot;control&quot;, &quot;B35&quot;, &quot;A12&quot;, &quot;T99&quot;)) table(clones_f_ord) Las variables numéricas y de caracteres se pueden convertir en factores (factorizar), pero los niveles de un factor siempre serán valores de caracteres. Podremos verlo en el siguiente ejemplo: vec &lt;- c(3, 5, 7, 1) sum(vec);mean(vec) vec_f &lt;- factor(vec) vec_f levels(vec_f) vec_n &lt;- as.numeric(vec_f) vec_f vec_n sum(vec_n); mean(vec_n) Hemos recuperado los valores numericos originales (vec)? que representan los numeros codificados por R en vec_f? vec_f1 = as.numeric(as.character(vec_f)) sum(vec_f1);mean(vec_f1) Indexación y &lt;- 1:10 y[ ] y[2] y[1:3] Seleccione los elementos 1° y 3° Condición # ifelse(condición, valor_si_TRUE, valor_si_FALSE) ifelse(y&lt;2, &quot;Low&quot;, &quot;High&quot;) Se evaluaron 10 clones de porta-injertos de cítricos según su resistencia a Gomosis del Tronco (Phytophthora parasitica). Los diámetros de la lesión (cm) en el punto de inoculación fueron: 3, 6, 1, 10, 3, 15, 5, 8, 19, 11. Crear un vector “resist” con las categorías S o R, “S” aquellos clones con lesiones por encima de la mediana, y “R” clones con lesiones por debajo de la mediana. 3.1.3 Valores especiales Existen valores reservados para representar datos faltantes, infinitos, e indefiniciones matemáticas. NA (Not Available) significa dato faltante/indisponible. El NA tiene una clase, o sea, pueden ser NA numeric, NA character, etc. y &lt;- c(2, 4, NA, 6) is.na(y) Calcule el promedio de y (use la ayuda de R en caso necesario)mean(y) NaN (Not a Number) es el resultado de una operación matemática inválida, ej: 0/0 y log(-1). Un NaN es un NA, pero no reciprocamente. 0/0 is.nan(0/0) is.na(0/0) NULL es el vacio de R. Es como si el objeto no existiese a = NULL a Inf (infinito). Es el resultado de operaciones matemáticas cuyo limite es infinito, es decir, es un número muy grande, por ejemplo, 1/0 o 10^310. Acepta signo negativo -Inf. 1/0 1/Inf References "],
["estructura-de-datos.html", "3.2 Estructura de datos", " 3.2 Estructura de datos 3.2.1 Data frames Conjunto de observaciones (filas) y variables (columnas). A diferencia que en las matrices, las columnas pueden tener diferentes tipos (clases) de variables como por ejemplo numéricas, categóricas, lógicas, fechas. Un dataframe es completo con dimensiones n_fila x p_columna, donde: 1- Cada fila debe contener toda la info de la unidad experimental que se está evaluando 2- Cada columna representa una variable (descriptiva o respuesta) 3- Cada celda debe tener su observación (en caso de faltar el dato será un NA) En numerosos paquetes de R, hay data frames disponibles para ejemplos de aplicación de funciones. Un ejemplo muy usado, que está en el paquete base es el dataset “iris”. ?iris View(iris) # ya activo desde inicio de sesión por default Explore el dataset iris con las siguientes funciones con iris y anote sus resultados: head(); tail(); dim(); names(); str(); row.names() Filtrado de datasets data[fila, columna] iris[1,] iris[,1] iris[1,1] iris$Sepal.Length levels(iris$Species) summary(iris$Sepal.Length) Selecione la segunda i) fila; ii) columna. iii) Seleccione la observación ubicada en la 2° fila y 3° columna iv) Seleccione las observaciones de las lineas 50 a 60 de las columnas 3 y 4. Función subset Filtremos a la variedad Species reteniendo solo a “setosa” iris_setosa &lt;- subset(iris, Species==&quot;setosa&quot;) Filtremos a la variedad Species reteniendo solo a “setosa” + “virginica” iris_set.virginica &lt;- subset(iris, Species %in% c(&quot;setosa&quot;, &quot;virginica&quot;)) Agreguemos una condición: a lo anterior quedemonos con aquellas filas en que Sepal.Length &gt; 5 iris2 &lt;- subset(iris, Species %in% c(&quot;setosa&quot;, &quot;virginica&quot;) &amp; Sepal.Length &gt; 5) Que pasa si cambiamos el operador &amp; por |? 3.2.2 Listas Objetos que aceptan elementos de clases diferentes. x &lt;- list(a = 1:5, b = c(&quot;a&quot;, &quot;b&quot;), c = TRUE) x (Mas info de subsetting elementos de una lista aqui) x$a # x[1] # #sum(x[1]) x[[1]] # sum(x[[1]]) x[&quot;c&quot;] # 3.2.3 Matrices Indicamos el número de filas con el argumento nrow y con ncol el número de columnas; luego indicamos que valores forman la matriz (del 1 al 9), y le hemos pedido a R que use esos valores para rellenar la matriz A por filas con byrow=TRUE. La matriz A así construida es: A &lt;- matrix(nrow=3, ncol=3, c(1,2,3,4,5,6,7,8,9), byrow=TRUE) Al igual que para los dataframes, se pueden seleccionar partes de una matriz utilizando los índices de posición [fila, columna] entre corchetes. A[2,3] # Se selecciona el valor de la fila 2, columna 3 "],
["import.html", "4 Importación de datos", " 4 Importación de datos Luego del planteo de hipótesis y planificación experimental, la toma de datos es una etapa determinante para el resto de flujo de trabajo. Un buen diseño experimental, con correcta toma de datos de calidad, no garantizan, pero si aumentan significativamente las probabilidades que nuestro trabajo goce de buen porvenir. Conocer las distintas etapas del workflow de investigación confiere la gran ventaja de poder pensar nuestras acciones como parte de un todo, y no como algo aislado. Por ejemplo, una planilla de campo de papel de formato apaisado (“wide”) puede que aún no esté lista para ser analizada, pero este formato confiere ciertas ventajas prácticas (confección de planilla de papel, control interno de las evaluaciones, pasaje a planilla electrónica). Por lo tanto en una siguiente etapa luego de la importación al entorno de nuestra sesión, puede que necesitemos re-estructurarla y asi poder continuar hacia la exploración. Podemos tomar esta planilla modelo, para entender como es una planilla para ser analizada en R. Veamos 4 Principios básicos de buenas prácticas en la elaboración de planillas de datos - Adaptado de (Broman and Woo 2018) Como regla global, y siguiendo lo ya comentado en la sección de data frames, columnas (Verticales) son Variables y filas (horizontales) son observaciones (generalmente de unidades experimentales/sujetos individuales) 1 - Consistencia Sean creativos al nombrar las variables: usen 3-4 letras (minúsculas) por palabra y en caso de necesitar usar “_”. No usar acentos ni ñ. Nunca dejen espacios y maximicen el ahorro de letras, siempre y cuando se justifique: severidad = sev incidencia = inc rendimiento = rto hoja = hj (bien podría ser “hoja” también) planta = pl bloque = bq placa = placa temperatura = temp máxima = max En particular prefiero usar el inglés, ya que no tiene acentos ni caracteres especiales. Siempre, siempre, identifiquen hasta el más mínimo detalle de las unidades experimentales (placas, macetas, plantas dentro de las macetas, etc.), al final se recuperará en creces el tiempo extra inicialmente invertido en ello (stand-alone). Adopten siempre los mismos términos No escatimen en columnas: rep_pl -&gt; rep | pl Crear diccionario de términos: Agreguen una planilla con el detalle por extenso de las variables y sus unidades. Piensen que esa planilla la debería entender cualquier persona sin auxilio de sus propios comentarios. 2 - Rectangular Todo set de datos tiene sus dimensiones específicas: n fila - n columnas. Si se perdió alguna parcela/planta por algún motivo extra-tratamiento simplemente es un NA, y asi deben definir esa observación, no poner “muerta” o “perdida” 3 - Cero es un dato! Cero no significa ausencia de observación, en este caso podemos usar “NA”, “-”, “.” o dejar en blanco (si se usa .xlsx) En preferencia, llenen todas las celdas, pero siempre un solo dato por celda… 4 - Planilla plana -&gt; DATOS CRUDOS SIN FORMULAS No combinar celdas no resaltar no hacer bordes sin negritas caracteres puros References "],
["vias-de-importacion.html", "4.1 Vías de importación", " 4.1 Vías de importación Son múltiples las necesidades y vías de importación de datos a nuestro entorno de sesión de R. Principalmente usaremos planillas excel guardados en nuestra computadora. Estos pueden estar guardados en formato .xlsx (planillas tradicionales) o .csv (texto separado con comas, mucho más livianos). La forma más rápida es vía clicks de mouse en el panel de entorno de la sesión: Buscan el archivo a importar en el explorador de archivos del panel multipropósito de RStudio Hacen click sobre el archivo Seleccionan “import dataset” Configuran las opciones de importación y copian el codigo generado y dan import (es aconsejable que peguen el codigo en el script de la sesión) O bien desde código del script: Archivos excel Importar soja_mancha.xlsx, nombrandolo “soja” Importar can_phoma.xlsx, nombrandolo “canola” Dataset canola_phoma Experimento de canola conducido en Balcarce, donde fueron testeados 10 fungicidas (mas un control sin protección con fungicida) con 3 bloques en que se registró el progreso de manchas foliares de Phoma lingam a través del tiempo (tiempo termico desde la detección de la primera mancha), y la severidad del consiguiente cancro desarrollado en la base del tallo. Dataset soja_mancha Experimentos individuales en microparcelas correspondientes a la Red de ensayos uniformes coordinada por EMBRAPA Soja (Brasil) de fungicidas para el control de mancha anillada en soja study: identificador arbitrario para cada experimento year: año del experimento location: localidad del experimento cultivar: cultivar de soja utilizado fungic: tratamiento fungicida block: repeticiones sev: severidad (%) evaluada en R6 yield: rendimiento en madurez fisiológica (kg/ha) Dataset olivo_xylella Datos simulados de muestreos de severidad de xylella en localidades productoras de olivo en Córdoba y La Rioja Archivos de texto .csv dat &lt;- read.csv(&quot;nombre_del_archivo.csv&quot;, header = TRUE, sep = &quot;,&quot;, dec = &quot;.&quot;)# puede variar el simbolo de como se separan las columnas. Siempre chequear el banco de datos importados. dat &lt;- readr::read_csv(&quot;ruta/nombre_del_archivo.csv&quot;) Desde clipboard Muchas veces necesitamos replicar rapidamente un fragmento del dataset desde excel, o bien un vector lo que es posible mediante: dat = read.delim(&quot;clipboard&quot;, dec=&quot;,&quot;) {datapasta} - Package + addin install.packages(&quot;datapasta&quot;) Desde google sheets: # install.packages(&quot;gsheet&quot;) url &lt;- &quot;https://docs.google.com/spreadsheets/d/1NQ7nd2pOPQYaLzJs1D2-aOB6LDKzv9kjOcKaNeNFjpA/edit?usp=sharing&quot; # browseURL(url) dat &lt;- gsheet::gsheet2tbl(url) dat Crear dataframes tipo SAS (bueno para crear ejemplos reproducibles) dat &lt;- read.table(header=T, text=&#39; Crop x1 x2 x3 x4 Corn 16 27 31 33 Corn 15 23 30 30 Corn 16 27 27 26 Corn 18 20 25 23 Corn 15 15 31 32 Corn 15 32 32 15 Corn 12 15 16 73 Soybean 20 23 23 25 Soybean 24 24 25 32 Soybean 21 25 23 24 Soybean 27 45 24 12 Soybean 12 13 15 42 Soybean 22 32 31 43 &#39;) Colección de datos en archivo .RData Muchas veces en una misma sesión se generan nuevos datasets a partir de uno importado. Al reiniciar una sesión deberia tenerse rapidamente disponibles todos los objetos creados en días previos los que pueden recopilarse en un archivo de múltiples objetos “.RData” e importarse directamente desde éste. save(soja, canola, file=&quot;./data/soja_canola.RData&quot;) Para traerlos nuevamente al entorno de la sesión: load(&quot;./data/soja_canola.RData&quot;) Exportar datasets write.table(dat, &quot;./data/dat.txt&quot;, sep = &quot;\\t&quot;) "],
["manip.html", "5 Manipular", " 5 Manipular Muchas veces los datos que importamos ya están listos para ser explorados y analizados. Otras veces precisan ser manipulados previamente para ello. En estos casos se parte de un dataset “crudo” y se transforma hacia un dataset “analítico”. tidyr y dplyr integran parte de la colección de paquetes de tidyverse y facilitan la manipulación de los data frames (Wickham and Grolemund 2016) library(tidyverse) Ambos paquetes utilizan el operador %&gt;% (pipe, tubo en español) lo que proporcionan una mejor interpretación lógica: utiliza el resultado de su lado izquierdo como primer argumento de la función del lado derecho (asemejándose a una receta de torta…) x &lt;- c(1, 2, 3, 4) x %&gt;% sum %&gt;% sqrt Su equivalente de código básico es: sqrt(sum(x)) Importemos los datos “crudos” que tenemos almacenados en el archivo .RData load(&quot;./data/datos_curso.RData&quot;) # browseURL(&quot;https://osf.io/jpfet/&quot;) References "],
["tidyr.html", "5.1 tidyr::", " 5.1 tidyr:: Las principales funciones son: gather spread separate unite join join Por lo general en la etapa de toma de datos en el campo/lab (y su consiguiente pasaje a planilla electrónica, excel) nos resulta más cómodo que las planillas de papel tengan un formato wide. En muchas ocasiones necesitamos (para graficar o modelar) que nuestros datos esten en formato long. Veamos de que se tratan ambos formatos. Datos canola: Para analizar el efecto del tratamiento fungicida necesitamos calcular el área bajo la curva (AUC) del progreso de la enfermedad. Para esto vamos a transponer can_phoma al formato “long”. La función gather (del inglés “reunir”, paquete tidyr) apila las columnas que indiquemos. canola %&gt;% select(-sev_cank) %&gt;% gather(key = var, value = inc, contains(&quot;inc&quot;)) %&gt;% separate(var, c(NA, &quot;tt&quot;), sep = &#39;_&#39;) -&gt; can_long Datos olivo olivo %&gt;% gather(`1`: `30`, key = &quot;tree&quot;, value = &quot;sev&quot;) -&gt; oli_long Datos soja soja %&gt;% gather(key = var, value = val, -fungic) %&gt;% separate(var, c(&#39;bk&#39;, &#39;x&#39;), sep = &#39;_&#39;, convert = TRUE) %&gt;% spread(x, val, convert = TRUE) -&gt; soja_long "],
["dplyr.html", "5.2 dplyr::", " 5.2 dplyr:: Los cinco verbos (funciones) principales de dplyr son: select filter mutate arrange summarise join junta dos data frames a través de puntos en común. Por ejemplo, si queremos unir las variables “sev_check” y “Dis_level” al dataset soja: soja %&gt;% inner_join(by_check, by=&quot;study&quot;) 5.2.1 select Vamos a seleccionar las variables: study, year, cultivar, fungic, rep, sev y yield. soja %&gt;% select(study, year, cultivar, fungic, rep, sev, yield) Es posible usar intervalos de varibles con :. Una selección “negativa” de las variables no deseadas daría un mismo resultado: soja %&gt;% select(-Yld_level, -YR_class, -gr_hab, -sev_check) 5.2.2 filter Semejante a subset. Condiciones separadas por comas equivalen a &amp; de subset. Filtremos la variable fungicida (fungic) por el testigo (ZZ_CHECK) soja %&gt;% select(study:yield) %&gt;% filter(fungic == &#39;ZZ_CHECK&#39;) Ahora, agreguemos el fungicida carbendazim a dosis de 1 litro (CZM[1]) al dataset soja %&gt;% select(study:yield) %&gt;% filter(fungic %in% c(&quot;ZZ_CHECK&quot;,&quot;CZM[1]&quot;)) 5.2.3 mutate Alistar los tipos de variables recien importados Haremos que las variables tipo caracter sean convertidas a factores: soja_long &lt;- soja_long %&gt;% mutate_at(vars(fungic:bk), funs(as.factor)) str(soja_long) summary(soja_long) can_long &lt;- can_long %&gt;% mutate_at(vars(trt, bk), funs(as.factor)) %&gt;% mutate_at(vars(tt, inc), funs(as.numeric)) str(can_long) oli_long &lt;- oli_long %&gt;% mutate_at(vars(loc, farm, tree), funs(as.factor)) str(oli_long) Luego de haber chequeado los tipos de datos con str() agregamos al archivo “datos_curso.RData” los nuevos archivos \"_long\", asi quedan disponibles rápidamente para las siguientes etapas save(soja, canola, mani, olivo, soja_long, can_long, oli_long, file=&quot;data/datos_curso.RData&quot;) Creación de nuevas variables (a partir de las existentes) Muchas variables biológicas no cumplen con los supuestos de las pruebas estadísticas paramétricas: no se distribuyen normalmente, las desviaciones estándar no son homogéneas, o ambas. Hay extensa bibliografia al respecto, recomendando cual transformación es la más adecuada para cada tipo de variable y asi poder ser analizada por un ANOVA tradicional (paramétrico). Como fitopatólogos, la no normalidad es lo predominante. El caso mas común es la severidad de enfermedades que comparamos a través de diferentes tratamientos (cultivar, fungicida, practica de manejo, etc.) Dos transformaciones son mayormente sugeridas para la severidad: Transformacion Arcsine:consiste en tomar el arcoseno de la raiz cuadrada de un numero. Transformación logit: soja1 &lt;- soja %&gt;% select(study:yield) %&gt;% filter(fungic %in% c(&quot;ZZ_CHECK&quot;,&quot;CZM[1]&quot;)) %&gt;% mutate(sev_arc = asin(sqrt(sev/100)), sev_logit = car::logit(sev, percents=TRUE),# log(sev/100/(1-sev/100)), # yield_tn = yield/1000) # browseURL(&quot;http://strata.uga.edu/8370/rtips/proportions.html&quot;) soja &lt;- readr::read_csv(&quot;data/soja_mancha.csv&quot;) soja &lt;- soja %&gt;% mutate_if(is.character, as.factor) 5.2.4 arrange Ordena crecientemente de acuerdo a la columna que le indiquemos. Utilizar desc para orden decrescente. soja1 %&gt;% arrange(year, cultivar) soja1 %&gt;% arrange(year, desc(cultivar)) 5.2.5 summarise Generalmente acompañada de la función group_by la cual permite aplicar un cálculo a las observaciones agrupando por niveles de algún factor (equivale a una tabla dinámica de excel) Veamos cuanto fue el rendimiento promedio y el desvio standard para cada fungicida a través de todos los ensayos: soja %&gt;% group_by(fungic) %&gt;% summarise(yield_mean = mean(yield), yield_sd = sd(yield)) Calculen el rendimiento mínimo y máximo por fungicida Algunas funciones interesantes para la descripción del dataset: n(), n_distinct(). Cuantos ensayos fueron realizados por año: soja %&gt;% group_by(year) %&gt;% summarize(n = n_distinct(study)) Cuantas parcelas tenia cada ensayo: soja %&gt;% group_by(study, year, cultivar) %&gt;% summarize(plots = n()) Adicione una columna de potencial de rendimento del ensayo (rend_pot), considerando el máximo rendimiento observado en ese ensayo. Usando la función ifelse cree una nueva variable categórica “presión de enfermedad” considerando a “sev_check”: Low o High by_check = soja %&gt;% filter(fungic==&quot;ZZ_CHECK&quot;) %&gt;% group_by(study) %&gt;% summarize(sev_check = round(mean(sev, na.rm = TRUE),1)) %&gt;% mutate(Dis_level = ifelse(sev_check &lt; 30, &quot;Low&quot;, &quot;High&quot;)) "],
["forcats.html", "5.3 forcats::", " 5.3 forcats:: Es un excelente aliado para manipular factores, principalmente cuando de graficar se trata. link install.packages(&quot;questionr&quot;) library(forcats) dat %&gt;% mutate(trt1= fct_recode(trt, `Czm` = &quot;CZM[1]&quot;, # `nombre_nuevo` = &quot;nombre_original&quot; `Czm+CM+Tebu` = &quot;CZM_CM_TEBU[1]&quot;, `Epo+Flux+Pyra (0.8L)` = &quot;EPO_FLUX_PYRA[0.8]&quot;, `Check` = &quot;ZZ_CHECK&quot;), trt1= fct_relevel(trt, # Asignar a trt1 nuevo orden de los factores &quot;Check&quot;, &quot;Czm&quot;, &quot;Czm+CM+Tebu&quot;, &quot;Epo+Flux+Pyra (0.8L)&quot;)) %&gt;% ggplot(aes(x, y)) + geom_boxplot()+ load(&quot;data/datos_crudos.RData&quot;) "],
["fitopato.html", "6 Cálculos fitopatométricos", " 6 Cálculos fitopatométricos Fitopatometría: La rama de la fitopatología que se ocupa de la teoría y la práctica de la evaluación cuantitativa de enfermedades (y/o patógenos). Nivel de planta individual Severidad: medida de la cantidad de enfermedad por unidad de muestreo (planta, m² de cultivo, fruto, etc.) . En fitopatología es comúnmente definida como el área (volumen) de tejido enfermo dividido por el total del área (volumen) (x100 para obtener un valor en porcentaje) Nivel de parcela / lote Incidencia: número de unidades muestreales (plantas) que están enfermas o infectadas por un agente patogénico. Expresado como un porcentaje (%) o proporción (0-&gt;1) del número total de unidades evaluadas. Indice de severidad: Estimación de severidad usando una escala de severidad que comprende una serie de intervalos de rangos numéricos. Por ej: grado rango de severidad ----- ------------------ 0 0 1 0&lt;=25% 2 25&lt;=50% 3 50&lt;=75% 4 75&lt;=100% La propuesta de Madden, Hughes, and Van Den Bosch (2007) (Cap. 2, pág. 20) es corregir por el punto medio del rango de severidad: \\(IS(\\%)=\\frac {\\sum frecuencia \\: de \\: grado\\: \\times\\: punto \\: medio \\: del \\: grado \\:de\\: escala} {total \\: plantas \\: evaluadas \\times 100}\\) Nivel de región Prevalencia: número de unidades de muestreo geográficas (lotes, campos, municipios, estados, regiones, etc.) donde se detectó una enfermedad o un patógeno, dividido por el número total de unidades de muestreo geográficas evaluadas. References "],
["caso-1-carbon-del-mani.html", "6.1 Caso 1: carbón del mani", " 6.1 Caso 1: carbón del mani mani &lt;- mani %&gt;% mutate_at(vars(c(&quot;trt&quot;, &quot;sprays&quot;, &quot;bk&quot;)),funs(factor)) mani Exploramos cuantas plantas (sub-muestra) fueron evaluadas por parcela: mani %&gt;% group_by(trt, sprays, bk)%&gt;% summarise(n=n()) #%&gt;% knitr::kable() Calculamos la incidencia por parcela y agregamos una columna para identificar a la planta como sub-muestra dentro de cada parcela: mani1 &lt;- mani %&gt;% mutate( trt = relevel(trt, ref=&quot;check&quot;), dis_pod = rowSums(select(., matches(&#39;x1|x2|x3|x4&#39;))), inc = dis_pod/n_pods, x0_p = rowSums(select(., matches(&#39;x0&#39;)))/n_pods, x3.4 = rowSums(select(., matches(&#39;x3|x4&#39;))), sev0_1 = (0*x0 + 0.01*x1 +0.1*x2 + 0.7*x3 + 1*x4)/ n_pods) %&gt;% group_by(sprays, trt, bk) %&gt;% mutate(sample = row_number()) %&gt;% # filter(sprays!=1, # trt!=&quot;Epoxiconazole&quot;) %&gt;% ungroup mani1 Calcularemos un valor de AUC por parcela con auxilio de las funciones group_by y summarize # if(require(MESS)) {install.packages(&quot;MESS&quot;)} can_long %&gt;% group_by(trt, bk) %&gt;% summarize(AUC = MESS::auc(inc, tt)) "],
["caso-2-xylella-en-olivos.html", "6.2 Caso 2: xylella en olivos", " 6.2 Caso 2: xylella en olivos Chequeamos cuantos árboles fueron evaluados en cada año/región/lote: ftable(xtabs(~year+loc+farm, olivo)) Imprimimos los 30 árboles de un mismo lote olivo %&gt;% arrange(loc, year) %&gt;% print(n=30) 6.2.1 Incidencia (nivel lote - evolución interanual) dat_inc &lt;- olivo %&gt;% group_by(year, loc, farm) %&gt;% summarise(inc = mean(sev&gt;0, na.rm=TRUE)*100) %&gt;% ungroup %&gt;% arrange(loc, year) dat_inc ggplot(dat_inc, aes(x=factor(year), y=inc, color=factor(farm))) + geom_point() + geom_line(aes(group=farm)) + facet_grid(. ~ loc) 6.2.2 Prevalencia (nivel región - evolución interanual) dat_prev &lt;- dat_inc %&gt;% group_by(year, loc) %&gt;% summarise(prev = trunc(mean(inc&gt;0, na.rm=TRUE)*100)) %&gt;% ungroup %&gt;% arrange(loc,year) dat_prev ggplot(dat_prev, aes(x=factor(year), y=prev, color=factor(loc))) + geom_point() + geom_line(aes(group=loc)) "],
["explore.html", "7 Visualizar", " 7 Visualizar La visualización de datos es una pieza fundamental del flujo de trabajo del científico, tanto para explorar sus observaciones, como para explicar/comunicar sus resultados e ideas. Es decir, dominar las herramientas de visualización resulta imprescindible para un investigador cuya materia prima son los datos. La gran comunidad de usuarios de R disponibiliza sus creaciones e incluso trabajan en extensiones que amplien la potencialidad de sus paquetes. Se podria afirmar que no hay límites para la creación. Digamos, que no importa el “Cómo?” si no el “Qué?” Algunas pruebas de ello son los siguientes links: The R Graph Gallery Top 50 plots Extensiones de ggplot Fundamentals of Data Visualization El paquete ggplot2 tiene una flexibilidad tal que permite generar rápidamente gráficos exploratorios asi como crear figuras complejas, detalladas de alta calidad (con fines de publicaciones científicas). "],
["ambas-variables-continuas.html", "7.1 Ambas variables continuas", " 7.1 Ambas variables continuas library(tidyverse) Tiene una gramática propia y la idea original es que un gráfico puede ser elaborado a partir de la combinación de capas, pudiendo tener estas diferentes bases de datos y objetos gráficos (puntos, líneas, barras, etc). Agregaremos una a una las capas mencionadas en la figura. Estas no tienen un orden estricto, salvo la primera que debe ser ggplot() que es la funcion que inicializa un grafico. A esta estarán asociada el dataframe principal (ya que un mismo grafico acepta tomar información de distintos datasets), y las aesthetics que o sea pueden haber varias aesthetics Se definen con aes() Significado de aesthetic en ggplot: “Algo que se puede ver” Cada geom acepta un conjunto de aesthetics Ejemplos: + position (i.e., en el eje “x” y “y”) color (color “exterior”) fill (color “interior”) shape (de los puntos) linetype size iris %&gt;% ggplot(aes(x = Sepal.Length, y = Petal.Length)) geoms Objetos geometricos son la representación visual de las observaciones. En general los que le dan el nombre al tipo de gráfico. La lista de “geoms” aumenta día a día. iris %&gt;% ggplot(aes(x=Sepal.Length, y=Petal.Length)) + geom_point() iris %&gt;% ggplot(aes(x=Sepal.Length, y=Petal.Length)) + geom_point(aes(color = Species)) iris %&gt;% ggplot(aes(x=Sepal.Length, y=Petal.Length)) + geom_point(aes(color = Species))+ geom_smooth() iris %&gt;% ggplot(aes(x = Sepal.Length, y = Petal.Length, color = Species)) + geom_point()+ geom_smooth() facets Las facetas o “facets” en permiten dividir el mismo gráfico en diferentes niveles de un factor. p &lt;- iris %&gt;% ggplot(aes(x = Sepal.Length, y = Petal.Length)) + geom_point()+ geom_smooth(method = &quot;lm&quot;)+ facet_wrap(~Species) p theme Los temas (theme) son un conjunto de opciones predefinidas sobre la apariencia de los objetos en ggplot. El tema por defecto del ggplot dibuja el gráfico sobre un fondo gris. Podemos cambiarlo a blanco y negro añadiendo el comando theme_bw() p + theme_bw() Si deseamos explorar las distribuciones de las variables podemos optar por un histograma o por diagramas de densidad cowplot::plot_grid( iris %&gt;% ggplot(aes(Petal.Length, fill=Species)) + geom_histogram()+ guides(fill=FALSE) , iris %&gt;% ggplot(aes(Petal.Length, fill=Species)) + geom_density(alpha=0.7) , align=&quot;h&quot; ) "],
["comparacion-de-niveles-de-factores.html", "7.2 Comparación de niveles de factores", " 7.2 Comparación de niveles de factores Los graficos de barra, ampliamente usados en publicaciones cientificas, son cada vez mas criticados por “ocultar” la naturaleza de las observaciones (Drummond and Vowler 2011; Weissgerber 2015) (Sugerencia: leer el box 1 del ultimo paper) De (Drummond and Vowler 2011): Fig 1. Many different datasets can lead to the same bar graph. The full data may suggest different conclusions from the summary statistics. The means and SEs for the four example datasets shown in Panels B–E are all within 0.5 units of the means and SEs shown in the bar graph (Panel A). p-values were calculated in R (version 3.0.3) using an unpaired t-test, an unpaired t-test with Welch’s correction for unequal variances, or a Wilcoxon rank sum test. - In Panel B, the distribution in both groups appears symmetric. Although the data suggest a small difference between groups, there is substantial overlap between groups. - In Panel C, the apparent difference between groups is driven by an outlier. - Panel D suggests a possible bimodal distribution. Additional data are needed to confirm that the distribution is bimodal and to determine whether this effect is explained by a covariate. - In Panel E, the smaller range of values in group two may simply be due to the fact that there are only three observations. Additional data for group two would be needed to determine whether the groups are actually different. A continuación presentamos algunas opciones gráficas que surgen de la combinación de medidas de posición y de dispersión. #Aprovechamos para customizar el `theme` a nuestro gusto y agregar algunos detalles: p0 &lt;- iris %&gt;% ggplot(aes(x=Species, y=Sepal.Length)) + labs(x = &quot;Iris species&quot;, y =&quot;Sepal length (cm)&quot;) + theme_light(base_size = 10) 7.2.1 Observaciones + media / mediana p1 &lt;-iris %&gt;% ggplot(aes(x=Species, y=Sepal.Length)) + geom_point(shape = 1, alpha=0.2)+ stat_summary(fun.y = mean, #median fun.ymin= mean, fun.ymax = mean, geom = &quot;point&quot;, size = 2)+ theme_light(base_size = 10)+ ggtitle(&quot;Observaciones (points) &amp; media&quot;) p1 # geom_dotplot(aes(fill = Species), # Use fill = Species here not in ggplot() # binaxis = &quot;y&quot;, # which axis to bin along # binwidth = 0.1, # Minimal difference considered diffeerent # stackdir = &quot;center&quot; # Centered # ) p2 &lt;- iris %&gt;% ggplot(aes(x=Species, y=Sepal.Length)) + geom_jitter(width = 0.2, alpha=0.2)+ stat_summary(fun.y = mean, #median fun.ymin= mean, fun.ymax = mean, geom = &quot;crossbar&quot;, size = 0.5)+ theme_light(base_size = 10)+ ggtitle(&quot;Observaciones (jitter) &amp; media&quot;) p2 7.2.2 Barplot + SE p3 &lt;-iris %&gt;% ggplot(aes(x=Species, y=Sepal.Length)) + # geom_bar(stat=&quot;identity&quot;) + stat_summary(fun.y=mean, position=position_dodge(width=0.95),geom=&quot;bar&quot;, colour=&quot;black&quot;,fill=&quot;grey90&quot;)+ stat_summary(fun.data=mean_cl_normal, geom=&quot;errorbar&quot;, width=0.2) + theme_light(base_size = 10)+ ggtitle(&quot;Barplot &amp; SEM&quot;) # geom_text(data= let, aes(label = M, x= trt, y=1, hjust=0.5),size = 4) p3 7.2.3 Box-plot p4 &lt;-iris %&gt;% ggplot(aes(x=Species, y=Sepal.Length)) + geom_boxplot(fill = &quot;grey90&quot;) + theme_light(base_size = 10)+ ggtitle(&quot;Boxplot &amp; mean&quot;) p4 7.2.4 Violin plot p5 &lt;-iris %&gt;% ggplot(aes(x=Species, y=Sepal.Length)) + geom_violin(trim=FALSE,fill = &quot;grey90&quot;)+ theme_light(base_size = 10)+ ggtitle(&quot;Violin plot&quot;) p5 7.2.5 Media &amp; dispersión p6 &lt;-iris %&gt;% ggplot(aes(x=Species, y=Sepal.Length)) + stat_summary(fun.y=&quot;mean&quot;, geom=&quot;point&quot;, size=2)+ stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, width=0.2)+ stat_summary(fun.data= mean_sdl, geom = &quot;errorbar&quot;, color=&quot;red&quot;, width=0.2)+ stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, color=&quot;blue&quot;, width=0.2)+ theme_light(base_size = 10)+ ggtitle(&quot;Media + SE (negro) / SD (rojo) / 95% CI (negro)&quot;) p6 cowplot::plot_grid(p1, p2, p3, p4, p5, p6, ncol = 3, nrow = 2) Siguiendo el tutorial, reproducir el graficos de los 5 grupos, de observaciones independientes. References "],
["multivariado.html", "7.3 Multivariado", " 7.3 Multivariado library(ggplot2) corr &lt;- round(cor(iris[,-5]), 1) library(GGally) ggpairs(iris, columns = 1:4) ggpairs(iris, columns = 1:4, ggplot2::aes(colour=Species)) library(ggcorrplot) ggcorrplot(corr, p.mat = cor_pmat(iris[,-5]), hc.order = TRUE, type = &quot;lower&quot;, color = c(&quot;#FC4E07&quot;, &quot;white&quot;, &quot;#00AFBB&quot;), outline.col = &quot;white&quot;, lab = TRUE) library(FactoMineR) library(factoextra) iris.pca &lt;- PCA(iris[,-5], graph = FALSE) fviz_pca_var(iris.pca) fviz_pca_ind(iris.pca, col.ind.sup = &quot;blue&quot;, repel = FALSE) fviz_pca_biplot(iris.pca, geom.ind = &quot;point&quot; # Individuals ) fviz_pca_biplot(iris.pca, col.ind = iris$Species, palette = &quot;jco&quot;, addEllipses = TRUE, #ellipse.type = &quot;confidence&quot;, label = &quot;var&quot;, col.var = &quot;black&quot;, repel = TRUE, legend.title = &quot;Species&quot;) fviz_pca_biplot(iris.pca, # Individuals geom.ind = &quot;point&quot;, fill.ind = iris$Species, col.ind = &quot;black&quot;, pointshape = 21, pointsize = 2, palette = &quot;jco&quot;, addEllipses = TRUE, # Variables # alpha.var =&quot;contrib&quot;, col.var = &quot;contrib&quot;, gradient.cols = &quot;RdYlBu&quot;, legend.title = list(fill = &quot;Species&quot;, colour = &quot;Contribution&quot;) ) "],
["mapas.html", "7.4 Mapas", " 7.4 Mapas library(tidyverse) library(&quot;rnaturalearth&quot;) # library(&quot;rnaturalearthdata&quot;) library(&quot;sf&quot;) Ej 1: Provincias de Argentina theme_set(theme_bw()) arg = ne_states(country = &#39;argentina&#39;, returnclass = &quot;sf&quot;) arg %&gt;% ggplot() + geom_sf() + geom_text(aes(longitude, latitude, label = name_fr), colour = &quot;black&quot;, size=2) Ej 2: Mapa de prevalencia de enfermedades muni &lt;- st_read(&quot;/home/juan/Dropbox/maps/shp/muni/municipio.shp&quot;, quiet = T) # muni %&gt;% st_bbox() SEBA &lt;- muni %&gt;% cbind(., st_coordinates(st_centroid(muni$geometry))) %&gt;% filter(between(Y, -40, -37), between(X, -59, -57.5)) cancro &lt;- SEBA %&gt;% as_tibble %&gt;% select(IN1) %&gt;% mutate(preval_2015 = rnorm(6, 30, 10), preval_2016 = preval_2015*1.05 + rnorm(1, 3, 2) , preval_2017 = preval_2016*1.05 + rnorm(1, 3, 2), preval_2018 = preval_2017*1.05 + rnorm(1, 3, 2)) %&gt;% gather(preval_2015:preval_2018, key = var, val = prevalencia) %&gt;% separate(var, c(NA, &quot;mes&quot;), sep = &#39;_&#39;) %&gt;% mutate(mes = as.integer(mes)) %&gt;% arrange(IN1) cancro SEBA_cancro &lt;- SEBA %&gt;% left_join(cancro, by= &quot;IN1&quot;) %&gt;% mutate(NAM = case_when(NAM==&quot;General Alvarado&quot; ~ &quot;Gral\\nAlvarado&quot;, NAM==&quot;General Pueyrredón&quot; ~ &quot;Gral\\nPueyrredón&quot;, TRUE ~ as.character(.$NAM))) map1 &lt;- ggplot(SEBA_cancro) + geom_sf(data=SEBA)+ # coord_sf(xlim = c(-63.5, -56), ylim = c(-36, -40), expand = FALSE)+ geom_sf(aes(fill=prevalencia))+ scale_fill_gradient2(midpoint = 35, low = &#39;green2&#39;, mid = &#39;yellow&#39;, high = &#39;red3&#39;, na.value = &#39;gray95&#39;)+ geom_text(aes(x=X, y=Y, label= NAM), size = 3, color = &quot;darkblue&quot;, check_overlap = TRUE)+ # transition_states(mes)+ facet_wrap(&quot;mes&quot;)+ labs(title = &quot;Evolución de la prevalencia del cancro del tallo de girasol&quot;, x = NULL, y = NULL, fill = &quot;Prevalencia&quot;)+ theme_bw() "],
["fechas.html", "8 Manipular fechas", " 8 Manipular fechas Saber manipular variables de tipo fechas resulta de gran practicidad debido a que como investigadores del área de ciencias agrarias / biológicas lidiamos constantemente con el tiempo en nuestros experimentos. Aprovechar las nuevas funciones de los paquetes de R que permiten realizar cálculos o graficas variables de tipo fechas nos optimizará nuestro trabajo cotidiano ya que nos evitará tener que realizar cálculos intermedios para convertir las fechas a días, ya que R hará ese trabajo invisiblemente (y sin errores). A continuación haremos una demostración simple de cómo operar con fechas involucrando a variables meteorológicas y de fenología de cultivos. "],
["analisis-de-temperaturas.html", "8.1 Análisis de temperaturas", " 8.1 Análisis de temperaturas Importamos un dataset de datos meteorológicos de Balcarce desde 1971 a 2019 bce &lt;- readxl::read_excel(&quot;./data/bce_clima.xlsx&quot;) %&gt;% mutate(year = lubridate::year(date), month = lubridate::month(date), julian = lubridate::yday(date)) head(bce) tail(bce) Construimos la banda central de medias minimas y maximas de cada dia bce_serie &lt;- bce %&gt;% filter(year&lt;2018) %&gt;% group_by(julian) %&gt;% summarise( month = first(month), avg = mean(tmean, .2, na.rm = T), # Rango 80% de los años (rango interno) lower_80=quantile(tmean, .2, na.rm = T), upper_80=quantile(tmean, .8, na.rm = T), # Min y max de tmean (rango externo) lower_tmean=min(tmean, na.rm = T), upper_tmean=max(tmean, na.rm = T)) %&gt;% ungroup() bce_serie Filtramos el dataset para la reciente campaña de grano grueso (primavera- verano - otoño) bce_18_19 &lt;- bce %&gt;% filter(date &gt; &#39;2018-08-31&#39;, date &lt; &#39;2019-03-30&#39;) %&gt;% left_join(bce_serie, by = c(&quot;julian&quot;, &quot;month&quot;)) %&gt;% mutate(date = as.Date(date)) %&gt;% droplevels() bce_18_19 Graficamos las bandas de 80% de la temperatura media diaria de la serie histórica y loas temperaturas medias observadas en la reciente campaña p1 &lt;- ggplot(bce_18_19, aes(x=date)) + geom_linerange(aes(ymin=avg, ymax=upper_tmean), colour = &quot;red&quot;, alpha=.2)+ geom_linerange(aes(ymin=lower_tmean, ymax=avg), colour = &quot;blue&quot;, alpha=.2) + geom_linerange(aes(ymin=lower_80, ymax=upper_80), colour = &quot;wheat4&quot;)+ geom_line(aes(y = tmean)) + scale_y_continuous(labels = numform::f_celcius, limits = c(0, 30), expand = c(0.05, 0))+ scale_x_date(date_breaks = &quot;1 month&quot;, date_labels=&quot;%b&quot;, expand=expand_scale(0.01,0))+ theme_bw()+ theme(axis.text.x = element_text(hjust = -1.5), panel.grid.minor = element_blank(), panel.grid.major = element_line(linetype=&quot;dotted&quot;)) p1 Exploramos si huebieron días con temperatura media mayor o menor a la serie histórica rec_frio &lt;- bce_18_19[which(bce_18_19$tmean&lt;bce_18_19$lower_tmean),] rec_cal &lt;- bce_18_19[which(bce_18_19$tmean&gt;bce_18_19$upper_tmean),] En caso de haberlos los agregamos al grafico base así como las heladas meteorológicas (Tmín&lt;=0°C) o agrometeorológicas (Tmín&lt;=3°C) library(ggrepel) options(repr.plot.width = 2, repr.plot.height = 2) p2 &lt;- p1 + # Agregar medias record frío geom_point(data = rec_frio, aes(date, y = tmean), colour = &quot;blue&quot;) + geom_text_repel(data=rec_frio[1,], aes(y=tmean, label=&quot;Récord fríos&quot;), size=3, min.segment.length = unit(0, &#39;lines&#39;), nudge_y = -2, segment.color=&quot;grey50&quot;)+ # Agregar medias record cálido geom_point(data =rec_cal, aes(date, y = tmean), colour = &quot;red&quot;)+ geom_text_repel(data = rec_cal, aes(y=tmean, label=&quot;Récord cálido&quot;), size=3, min.segment.length = unit(0, &#39;lines&#39;), nudge_y=2, segment.color=&quot;grey50&quot;)+ # Agregar heladas meteorologicas y agrometeorológicas geom_point(data = bce_18_19[which(bce_18_19$tmin&lt;=0),], aes(date, y = 0), shape=8, colour = &quot;blue&quot;) + geom_point(data = bce_18_19[which(bce_18_19$tmin&gt;0 &amp; bce_18_19$tmin&lt;=3),], aes(date, y = 3.5), shape=8, colour = &quot;chartreuse&quot;)+ annotate(&quot;text&quot;, x = c(as.Date(&quot;2018-09-3&quot;), as.Date(&quot;2018-11-10&quot;)), y = c(0,3.5), label = c(&quot;Helada meteorológica&quot;,&quot;Heladas\\nagronómicas&quot;), size=3, hjust = 0) p2 Finalmente agregamos los estadíos reproductivos del cultivo de girasol Para ello haremos algunos cálculos con los intervalos de tiempo de los estadios reproductivos floración (r5) y llenado de granos (r6) r5 = c(as.Date(&quot;2018-12-15&quot;), as.Date(&quot;2019-01-15&quot;)); diff(r5) r6 = c(as.Date(&quot;2019-01-15&quot;), as.Date(&quot;2019-03-10&quot;)); diff(r6) midpoint &lt;- function(interval) { min(interval) + (max(interval) - min(interval))/2 } ; midpoint(r5) #ej p_final &lt;- p2 + # barras de floracion y llenado annotate(&quot;rect&quot;, xmin= c(min(r5), min(r6)), xmax=c(max(r5),max(r6)), ymin=0, ymax=30, alpha=0.2, fill=c(&quot;grey80&quot;,&quot;grey60&quot;))+ annotate(&quot;text&quot;, x = c(midpoint(r5), midpoint(r6)), y=3, label = c(&#39;bold(&quot;Floración&quot;)&#39;,&#39;bold(&quot;Llenado&quot;)&#39;), colour = &quot;red&quot;, parse = TRUE, size=3) + labs(x=NULL, y=NULL, title = &quot;Temperatura media en Balcarce y estadíos reproductivos del girasol&quot;, subtitle = &quot;- Campaña 2018/19 (línea negra)\\n- Serie 1971-2017: rango 80% (banda interna) y medias extremas (bandas externas)&quot;, caption = &quot;Datos registrados en la estación meteorológica de la EEA INTA Balcarce&quot;)+ theme(plot.caption = element_text(hjust = 0)) p_final "],
["analisis-de-precipitaciones.html", "8.2 Análisis de precipitaciones", " 8.2 Análisis de precipitaciones suppressWarnings(suppressMessages(library(&quot;tidyverse&quot;, quietly = T))) library(lubridate) bce &lt;- readxl::read_excel(&quot;./data/bce_clima.xlsx&quot;) %&gt;% mutate(year = lubridate::year(date), month = lubridate::month(date), julian = lubridate::yday(date)) Calculamos las lluvias acumuladas por decada Primero para la serie histórica bce_serie &lt;- bce %&gt;% filter(year!=2018) %&gt;% group_by(date=if_else(day(date) &gt;= 30, floor_date(date, &quot;20 days&quot;), floor_date(date, &quot;10 days&quot;))) %&gt;% summarize(rain_acum = sum(rain), days = n()) %&gt;% mutate(year = year(date), month = month(date)) %&gt;% # julian = yday(date)) %&gt;% ungroup %&gt;% group_by(year) %&gt;% mutate(decada = row_number()) %&gt;% ungroup %&gt;% group_by(decada) %&gt;% summarise(month = first(month), med = quantile(rain_acum, .5, na.rm = T), lower_80=quantile(rain_acum, .2, na.rm = T), # Rango 80% de los años upper_80=quantile(rain_acum, .8, na.rm = T)) Luego para la reciente campaña de grano grueso bce_18_19 &lt;- bce %&gt;% group_by(date = if_else(day(date) &gt;= 30, floor_date(date, &quot;20 days&quot;), floor_date(date, &quot;10 days&quot;))) %&gt;% summarize(rain_acum_season = sum(rain)) %&gt;% #, days=n()) %&gt;% mutate(year = year(date), month = month(date)) %&gt;% group_by(year) %&gt;% mutate(decada = row_number()) %&gt;% filter(date &gt; &#39;2018-08-31&#39;, date &lt; &#39;2019-03-30&#39;) Fusionamos ambos datasets en base al de la actual campaña (que es el que tiene las fechas) bce_18_19 &lt;- bce_18_19 %&gt;% left_join(bce_serie, by = c(&quot;decada&quot;)) %&gt;% mutate(date = as.Date(date)) # print(bce_18_19, n=Inf) Ya estamos en condiciones de graficar ambos datasets Configuramos el aspecto del gráfico theme_set(theme_bw() + theme(axis.text.x = element_text(hjust=-1.5), panel.grid.minor = element_blank(), panel.grid.major = element_line(linetype=&quot;dotted&quot;), plot.title = element_text(size = 11, face = &quot;bold&quot;), plot.caption = element_text(hjust=1))) # corregimos la posición de las barras desplazandolas hacia la derecha p_5=position_nudge(x = 5) (p1 &lt;- bce_18_19 %&gt;% ggplot(aes(x=date)) + geom_pointrange(aes(y=med, ymin=lower_80, ymax=upper_80), fill=&#39;white&#39;, color=&#39;deepskyblue&#39;, shape=21, fatten=.7, size=3, position=p_5)+ geom_point(aes(y=rain_acum_season), col =&quot;brown1&quot;, position=p_5) + geom_line(aes(y=rain_acum_season, group=1), col =&quot;brown1&quot;, linetype=&quot;dashed&quot;, position=p_5)+ scale_y_continuous(limits=c(0, 100), expand=c(0.05, 0))+ scale_x_date(date_breaks=&quot;1 month&quot;, date_labels=&quot;%b&quot;, expand=expand_scale(0.05,0)) ) Incluimos la fenología del girasol r5 = c(as.Date(&quot;2018-12-15&quot;), as.Date(&quot;2019-01-15&quot;)); diff(r5) r6 = c(as.Date(&quot;2019-01-15&quot;), as.Date(&quot;2019-03-10&quot;)); diff(r6) midpoint &lt;- function(interval) { min(interval)+(max(interval)-min(interval))/2 }; midpoint(r5) (p_final &lt;- p1 + annotate(&quot;rect&quot;, xmin= c(min(r5), min(r6)), xmax=c(max(r5),max(r6)), ymin=70, ymax=90, alpha=0.3, fill=c(&quot;grey80&quot;,&quot;grey60&quot;))+ annotate(&quot;text&quot;, x = c(midpoint(r5), midpoint(r6)), y=80,col=&quot;red&quot;, parse=TRUE, size=3, label=c(&#39;bold(&quot;Floración&quot;)&#39;,&#39;bold(&quot;Llenado&quot;)&#39;)) + labs(x=NULL, y=NULL, title=&quot;Precipitaciones decádicas en Balcarce y estadíos reproductivos del girasol&quot;, subtitle=&quot;- Campaña 2018/19 (en puntos rojos)\\n- Serie 1971-2017: mediana (puntos blancos) y rango 80% (barras azules)&quot;, caption=&quot;Datos registrados en la estación meteorológica de la EEA INTA Balcarce&quot;) ) # ggsave(file = &quot;plots/bce_lluvias.png&quot;, w=80, h=50, units=&quot;mm&quot;, dpi=300, scale=2) "],
["modelos.html", "9 Modelos", " 9 Modelos Lexturas recomendadas Analysis and Interpretation of Interactions in Agricultural Research Analysis of Combined Experiments Revisited Model Syntax in R ANOVA: A Short Intro Using R glmmFAQ A brief introduction to mixed effects modelling and multi-model inference in ecology Data Analysis Examples Data Analysis and Visualization in R for Ecologists RNAseq analysis with R "],
["modelos-lineales.html", "9.1 Modelos lineales", " 9.1 Modelos lineales Un solo factor - experimento DCA: dataset PlantGrowth ?PlantGrowth plant_g &lt;- PlantGrowth # simplificamos el nombre del dataset Exploración str(plant_g) # tipo de variables summary(plant_g) # exploración numérica # exploracion numerica por tratamiento plant_g %&gt;% group_by(group) %&gt;% summarise( count = n(), mean = mean(weight, na.rm = TRUE), sd = sd(weight, na.rm = TRUE) ) # Exploración gŕafica plant_g %&gt;% ggplot(aes(x=group, y=weight)) + geom_boxplot(width=0.2)+ geom_jitter(alpha=0.2, width=0.2)+ theme_light() Ajuste del modelo lineal \\[y_{ij} = \\mu + \\alpha_i + e_{ij}; \\:\\:i = 1,..., k; \\:j = 1,..., n\\] \\[N \\sim (\\sigma^2, 0)\\] mod1 &lt;- lm(weight ~ group, data = plant_g) Diagnósticos Las varianzas (entre niveles del factor) son homogéneas? # homocedasticidad plot(mod1, which = 1) car::leveneTest(mod1) Los residuos se distribuyen normales? plot(mod1, which = 2) shapiro.test(mod1$residuals) # my_data$fit = mod1$fitted.values # my_data$res = my_data$fit - my_data$weight # mean(my_data$res) # names(mod1)hist(m_fix$residuals) anova(mod1)# caso balanceado # car::Anova(mod1)# caso desbalanceado Test de comparación múltiple (de medias estimadas de los tratamientos) library(emmeans) em &lt;- emmeans(mod1, ~ group, type=&quot;response&quot;) em res = CLD(em, Letters = letters, reverse = FALSE, alpha = .05) res Dos factores: ?ToothGrowth tg &lt;- ToothGrowth Exploración str(tg) # tipo de variables tg &lt;- tg %&gt;% mutate_at(vars(dose), funs(as.factor)) summary(tg) # exploración numérica # exploracion numerica por tratamiento tg %&gt;% group_by(supp, dose) %&gt;% summarise( count = n(), mean = mean(len, na.rm = TRUE), sd = sd(len, na.rm = TRUE) ) # Exploración gŕafica tg %&gt;% ggplot(aes(x = factor(dose), y = len, colour = supp)) + geom_boxplot() + theme_bw() mod2 &lt;- lm(len ~ supp * dose, data = tg) # equivale a supp + dose + supp:dose anova(mod2) comparaciones múltiples (un factor dentro del otro) # emmip(mod2, supp~ dose) emm_tg &lt;- emmeans(mod2, pairwise ~ supp | dose) CLD(emm_tg, Letters = letters, reverse = FALSE, alpha = .05) emm_tg2 &lt;- emmeans(mod2, pairwise ~ dose|supp) CLD(emm_tg2, Letters = letters, reverse = FALSE, alpha = .05) Transformación potencia óptima de boxcox Esta transformación solo tiene un parámetro: lambda, graficado en el eje x. Si el valor de lambda es igual a cero, se lleva a cabo la transforma con el logaritmo natural, y si dicho valor es distinto a cero la transformación es potencial. Si el parámetro lambda es igual a uno, no hace falta transformar la variable respuesta. Si el intervalo (lineas punteadas verticales) no contiene a 0 ni a 1, hay que transformar la variable elevando a la potencia del valor de lamba incluido en el intervalo La utilización de la transformación Box-Cox requiere que todos los valores de la serie de entrada sean positivos y distintos a cero. Por ello es adicionada una constante a la variable original (0.5, por ej.) En el caso de la derecha, el modelo resultaria: lm((y+0.5)^0.2 ~ trt + bk, ...) "],
["glm.html", "9.2 GLM", " 9.2 GLM 9.2.1 Variable conteo ?InsectSprays ins_sp &lt;- InsectSprays ins_sp %&gt;% ggplot(aes(x=spray, y=count)) + geom_boxplot(width=0.2)+ geom_jitter(alpha=0.2, width=0.2)+ theme_light() ins_sp %&gt;% ggplot(aes(x=count)) + geom_dotplot()+ theme_light() Modelar como modelo lineal? plot(lm(count ~ spray, data = InsectSprays), which=2) # MASS::boxcox(lm(count+.1 ~ spray, data = InsectSprays)) # MASS::boxcox(lm(sqrt(count+.1) ~ spray, data = InsectSprays)) Ajuste de modelo lineal generalizado mod_spray = glm(count ~ spray, family=poisson, data=ins_sp) # full model car::Anova(mod_spray) Diagnóstico del modelo ggfortify::autoplot(mod_spray, which = 1:6, label.size = 3) Estimación de media de los tratamientos y comparaciones entre ellas library(emmeans) em_poi &lt;- emmeans(mod_spray, ~ spray, type=&quot;response&quot;) em_poi res_poi = CLD(em_poi, Letters = letters, reverse = FALSE, alpha = .05) res_poi "],
["links-de-interes.html", "10 Links de interés", " 10 Links de interés Otros cursos introductorios a R R for data scientists R4ULPGC: Introducción a R Modern dive R for Reproducible Scientific Analysis tutorialspoint Curso Emerson Del Ponte Recursos interesantes para el área de datos biológicos / fitopatolgía R for Plant Pathologists Open Plant Pathology Algunos inspiradores R users blogs Robin Choudhury Emi Tanaka Julia Stewart Zhian Kamvar Alejandro Rojas Referencias "]
]
