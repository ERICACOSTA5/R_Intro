[
["index.html", "Introducción a R para el análisis de datos de Ciencias Agrarias Motivación", " Introducción a R para el análisis de datos de Ciencias Agrarias Motivación “Una de las cosas más importantes que puedes hacer es dedicar un tiempo para aprender un lenguaje de programación. Aprender a programar es como aprender otro idioma: requiere tiempo y entrenamiento, y no hay resultados prácticos inmediatos. Pero si superas esa primera subida empinada de la curva de aprendizaje, las ganancias como científico son enormes. Programar no sólo te liberará de la camisa de fuerza de los softwares estadísticos cerrados, sino que también agudizará tus habilidades analíticas y ampliará los horizontes de modelado ecológico y estadístico.” ~ Adaptación de (Ellison and Gotelli 2004) ~ Podríamos resumir nuestro trabajo como científicos, desde la recolección de datos en el campo, hasta su divulgación a través del siguiente esquema: ~ Adaptación de “R for Data Science” (Wickham and Grolemund 2016) ~ Objetivos El curso pretende proveer herramientas de programación básicas para llevar adelante el proceso de investigación tomando como base el esquema de trabajo anterior. Para ello, usaremos datos (reales o simulados) típicos del área de Ciencias Agrarias. Importante: i) no es un curso de estadística; ii) entendemos la programación como un simple medio para optimizar nuestra labor cotidiana (no como un fin mismo), al final del día seguiremos siendo fitopatólogos, fisiólogos, bioquímicos, etc.; y iii) maximizaremos la adopción de la filosofia tidyverse Estas son algunas razones por la que elegimos R (R Core Team 2017) Software libre Aprender un lenguaje de programación: ejercicio mental/lógica. Aprender estadística resulta mucho mas ameno. Software actualizado y con una amplia gama de paquetes específicos (drc, agricolae, epiphy…) Gran flexibilidad y elegancia de los gráficos Comunidad activa y creciente dispuesta a ayudar (aprendemos a usar terminos técnicos de data science en inglés) Cronograma Horario Lunes Martes Miércoles Jueves Viernes 9:00 (10.30) 12.30 Intro R RStudio Importar Manipular Modelos lineales Gráficos II Reportes 13.30 (15:00) 16:00 Rcalc Objetos Explorar Modelos lineales Presentación de reportes Autor Juan Pablo Edwards Molina: Investigador - Epidemiología de enfermedades de cultivos (IPAVE / INTA). Email: edwardsmolina@gmail.com ORCID: https://orcid.org/0000-0002-3685-760X Twitter: juanchiedwards GitHub: https://github.com/juanchiem Este obra está licenciado com uma Licença Creative Commons Atribuição-NãoComercial-SemDerivações 4.0 Internacional. Referencias "],
["intro.html", "1 Introducción 1.1 Instalación de programas 1.2 Configuraciones básicas del RStudio 1.3 Instalación de paquetes 1.4 Configuración de la sesión", " 1 Introducción 1.1 Instalación de programas 1° R 2° R Studio (bajar la versión Free) 1.2 Configuraciones básicas del RStudio 1.3 Instalación de paquetes Existen varias vias de instalación de paquetes: Via CRAN (Comprehensive R Archive Network): install.packages(&quot;nombre_del_paquete&quot;) O simplemente en el panel de paquetes. Paquetes no oficiales via Github: devtools::install_github(&quot;rstudio/epiphy&quot;) Una vez instalado, hay que cargar los paquetes que contienen las funciones que vayamos a usar en cada sesión library(nombre-del-paquete) 1.4 Configuración de la sesión Varios tipos de archivos serán creados y usados durante una sesión de R: datos crudos (hojas de cálculo) - datos manipulados scripts gráficos reportes de resultados Una sesión de análisis debe poder ser retomada en cualquier momento pudiendo darse por concluída cuando el trabajo es publicado. Hasta entonces debemos tener rápido acceso a todos los objetos creados en sesiones anteriores. Para ello debemos manejarnos siempre bajo buenas prácticas de trabajo. Esto nos permitirá entender que quisimos hacer tiempo atrás, seremos intuitivos para encontrar archivos/objetos, y finalmente crearemos trabajos reproducibles… Una forma práctica de administrar todos los objetos que una sesión es crear un proyecto de R para cada sesión. Una sugerencia es generar subcarpetas en nuestras máquinas, en preferencia dentro de dropbox / google drive. Esto no solo mantendrá nuestro trabajo resguardado de posibles pérdidas (backup), retomarlo desde diferentes maquinas (trabajo/casa), sino que también le permitirá compartir en tiempo real sus avances con los colaboradores de su trabajo. Crear una carpeta Intro_R en sus máquinas Crear una nuevo proyecto “Intro_R.Rproj” Crear un script “1_intro” Donde se guardaria el siguiente gráfico? plot(pressure) "],
["r-como-calculadora.html", "2 R como calculadora 2.1 Tipos de Objetos 2.2 Funciones 2.3 S.O.S.!! 2.4 Tablas resumen", " 2 R como calculadora Ver tablas resumen de operadores aritméticos y lógicos (al final del capítulo) 4 + 9 4 - 3 * 1 # 4%1 4&gt;3 4 == 3 4 == 4 (4 + 5 ) * 7 - (36/18)^3 Está bien la siguiente expresión? 5 + 3 * 10 %/% 3 == 15 Agregue parentesis para que la expresión de un resultado contrario. Rendimiento de trigo en función de la severidad de fusariosis de la espiga (Madden and Paul 2009) El intercepto de la regresión lineal estimada (rendimiento de trigo libre de enfermedad) fue de 4.10 t/ha, y la pendiente fue de 0.038 t/ha por unidad de aumento de la severidad de la enfermedad. El tipo de trigo tuvo efecto significativo en el intercepto pero no en la pendiente: trigo de invierno tuvo, en promedio, 0.85 t/ha mas rendimiento que el trigo de primavera. 4.1 - 0.038 * 10 (1-(3.72/4.1))*100 Cuanto seria el rendimiento de ambas variedades de trigo con 1, 10 o 20% de severidad de la enfermedad? Algunos cálculos sqrt(3) # 3^0.5 2^(1/3) # ^(1/n) log(10) log(10, base=10) exp(1) log(10, base=exp(1)) exp(4) log10(10^4) round(4.3478, digits=3) # ceiling(4.3478) floor(4.3478) (Note que R está en inglés (decimales “.”, nombre de las funciones) y es “case sensitive”!!) 2.1 Tipos de Objetos atom &lt;- 3 atom El anterior ejemplo, guardamos el valor 3 en “atom”, y siempre que R encuentre ese nombre atom lo entenderá como un 3. Existen varias clases básicas o “atómicas” de elementos en R class(atom) 2.1.1 Vectores # concatenación de elementos atómicos v &lt;- c(8, 7, 9, 10, 10, 111) class(v) (b &lt;- c(&quot;A&quot;, &quot;b&quot;)) class(b) is.character(b) is.numeric(b) (m &lt;- c(TRUE, FALSE, T, F)) ; class(m) # Propiedades de v # ?length length(v) summary(v) #v &lt;- edit(v) sort(v) Operaciones con vectores v - 1 # Medidas de posición mean(v) median(v) # Medidas de dispersión var(v) sd(v) sqrt(var(v)) IQR(v) range(v) quantile(v, 0.1) ecdf(v)(7) max(v) min(v) sum(v) Cree tres nuevos vectores que sean: i) la potencia cuadrada de 3.5 de v; ii) la raiz cubica de v; iii) el logaritmo natural de la diferencia de i) y ii) Secuencia 1:7 seq(from = 0, to = 20, #by=2) # length=4) rep(1:3, times=3) # , each=3 Números aleatorios - distribuciones Tendencias genéticas y fenotípicas de características de crecimiento en el ganado brahman de registro de México (Parra-Bracamonte et al. 2007) set.seed(123) PesoNac &lt;- rnorm(23570, mean=32.2, sd=1.8) range(PesoNac) hist(PesoNac) hist(PesoNac, prob=TRUE) # add a density estimate with defaults lines(density(PesoNac), col=&quot;blue&quot;, lwd=2) Propiedades de vectores Si colocaramos dos o mas clases diferentes dentro de un mismo vector, R va forzar a que todos los elementos pasen a pertenecer a una misma clase. El número 1.7 cambiaria a “1.7” se fuera creado junto con “a”. y &lt;- c(1.7, &quot;a&quot;) ## character y &lt;- c(TRUE, 2) ## numeric y &lt;- c(TRUE, &quot;a&quot;) ## character Forzando las clases explicitamente as.character(), as.numeric(), as.integer() y as.logical() Factores Factores pueden ser considerados como vectores de enteros que poseen rótulos (labels). resist &lt;- c(&quot;R&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;R&quot;) class(resist) res_f &lt;- as.factor(resist) res_f as.numeric(res_f) table(resist) pie(table(resist)) barplot(table(resist)) De factor para numérico niv_res &lt;- factor(c(&quot;1&quot;, &quot;5&quot;, &quot;7&quot;, &quot;9&quot;)) sum(niv_res) niv_res1 = as.numeric(niv_res) mean(niv_res1) niv_res2 = as.numeric(as.character(niv_res)) mean(niv_res2) Indexación y[ ] y[2] y[1:3] Seleccione los elementos 1° y 3° Condición # ifelse(condición, valor_si_TRUE, valor_si_FALSE) ifelse(a&lt;2, &quot;Low&quot;, &quot;High&quot;) Se evaluaron 10 clones de porta-injertos de cítricos según su resistencia a Gomosis del Tronco (Phytophthora parasitica). Los diámetros de la lesión (cm) en el punto de inoculación fueron: 3, 6, 1, 10, 3, 15, 5, 8, 19, 11. Crear un vector “resist” con las categorías S o R, “S” aquellos clones con lesiones por encima de la mediana, y “R” clones con lesiones por debajo de la mediana. 2.1.2 Valores especiales Existen valores reservados para representar datos faltantes, infinitos, e indefiniciones matemáticas. NA (Not Available) significa dato faltante/indisponible. El NA tiene una clase, o sea, pueden ser NA numeric, NA character, etc. NaN (Not a Number) representa indefiniciones matemáticas, como 0/0 y log(-1). Un NaN es un NA, pero no reciprocamente. Inf (Infinito) es un número muy grande, por ejemplo, 1/0 o 10^310. Acepta signo negativo -Inf. NULL representa ausencia de información. # NaN es el resultado de una operación matemática inválida. Significa Not A Number 0/0 is.nan(0/0) is.na(0/0) # NULL es el vacio de R. Es como si el objeto no existiese a = NULL a # Inf significa infinito. Es el resultado de operaciones matemáticas cuyo limite es infinito. 1/0 1/Inf # NA es una constante lógica de R. Significa Not Available. NA puede ser # convertido para casi todos los tipos de vectores de R. Se usa principalmente para indicar valores faltantes. y &lt;- c(2, 4, NA, 6) is.na(y) mean(y) Calcule el promedio de y (use la ayuda de R en caso necesario) 2.1.3 Data frames Conjunto de observaciones (filas) y variables (columnas). A diferencia que en las matrices, las columnas pueden tener diferentes tipos (clases) de variables como por ejemplo numéricas, categóricas, lógicas, fechas. En numerosos paquetes de R, hay data frames disponibles para ejemplos de aplicación de funciones. Un ejemplo muy usado, que está en el paquete base es el dataset “iris”. ?iris iris # ya activo desde inicio de sesión por default Explore el dataset iris con las siguientes funciones con iris y anote sus resultados - head() - tail() - dim() - names() - str() 2.1.4 Filtrado de datasets data[fila, columna] iris[1,] iris[,1] iris[1,1] iris$Sepal.Length levels(iris$Species) summary(iris$Sepal.Length) Selecione la segunda i) fila; ii) columna. iii) Seleccione la observación ubicada en la 2° fila y 3° columna iv) Seleccione las observaciones de las lineas 50 a 60 de las columnas 3 y 4. Función subset Filtremos a la variedad Species reteniendo solo a “setosa” iris_setosa &lt;- subset(iris, Species==&quot;setosa&quot;) Filtremos a la variedad Species reteniendo solo a “setosa” + “virginica” iris_set.virginica &lt;- subset(iris, Species %in% c(&quot;setosa&quot;, &quot;virginica&quot;)) Agreguemos una condición: a lo anterior quedemonos con aquellas filas en que Sepal.Length &gt; 5 iris2 &lt;- subset(iris, Species %in% c(&quot;setosa&quot;, &quot;virginica&quot;) &amp; Sepal.Length &gt; 5) Que pasa si cambiamos el operador &amp; por |? 2.1.5 Listas Objetos que aceptan elementos de clases diferentes. x &lt;- list(a = 1:5, b = c(&quot;a&quot;, &quot;b&quot;), c = TRUE) x x$a # x[1] # #sum(x[1]) x[[1]] # sum(x[[1]]) x[&quot;c&quot;] # 2.2 Funciones Generalmente, el nombre de las funciones es intuitivo, por ejemplo, mean es la función que calcula la media, round es la funión que redondea un número. Los paquetes contienen conjuntos de funciones las cuales son específicas para ciertos procedimientos. numb &lt;- 1:6 round(mean(numb)) # floor() # ceiling() trunc() Si es necesario, se pueden crear funciones propias. Las funciones devuelven el último valor que se mostró y no modifican el ambiente de trabajo global, salvo que se lo explicite utilizando &lt;&lt;-. Estandarizar &lt;- function(x) { Media&lt;- mean(x) SD&lt;- sd(x) (x-Media)/SD } set.seed(pi) Estandarizar(rnorm(10,40,5)) 2.3 S.O.S.!! En el mismo R: ?auc; ??auc; F1 sobre la función Googlear: “r generate a sequence of uppercase letters” Stack Overflow: foros de pregunta y respuesta ampliamente utilizados por todos los lenguajes de programación. En algunos paises, llegan hasta a usar la reputación de los usuarios como diferencial en el currículum! ¿Cómo hacer una buena pregunta en el stack overflow? Ser consciso pero gentil… Ser reproducible: su código debe correr en cualquier maquina. La comunidad no irá a ayudarle si no pueden reproducir su error (detallar paquetes y version de R en caso necesario) library(reprex). 2.4 Tablas resumen Table 2.1: Operadores aritméticos Operador Detalle x + y Suma de x e y x - y Resta de x menos y x * y Multiplicación x / y División de x por y x %/% y Parte entera de la división de x por y x %% y Resto de la división de x por y x ^ y x elevado a y-ésima potencia Table 2.2: Operadores lógicos Operador Prueba.lógica x &lt; y x menor que y? x &lt;= y x menor o igual que y? x &gt; y x mayor que y? x &gt;= y x mayor o igual que y? x == y x igual que y? x != y x diferente que y? Table 2.3: Funciones matemáticas Operador Detalle sqrt(x) raiz de x exp(y) exponencial de y log(x) logaritmo natural de x = ln log10(x) Logaritmo base 10 de x sum(x) suma todos los elementos de x prod(x) producto de todos los elementos de x round(x, n) redondea x a n-digitos Table 2.4: Algunos atajos comúnentes usados Teclas Detalle Alt+Shift+K panel de todos los atajos Ctrl+Z / Ctrl+Shift+Z undo/redo Alt+ - &lt;- Ctrl+r corre la linea/bloque completa de codigo Ctrl+l limpia la consola Ctrl+Shift+c silencia la linea Ctrl+i indexa el bloque de código Referencias "],
["import.html", "3 Importar 3.1 Organización de planillas a ser importadas a R 3.2 Vías de importación", " 3 Importar 3.1 Organización de planillas a ser importadas a R Un primer paso en nuestras investigaciones (fundamental, determinante del resto de flujo de trabajo) es la toma de datos. Un buen diseño experimental, con correcta toma de datos de calidad, no garantizan, pero si aumentan significativamente las probabilidades que nuestro trabajo goze de buen porvenir. En particular prefiero que las planillas excel sean similares a las de campo (puede haber discrepancia) ya que muchas veces pedimos a otras personas que pasen los datos por nosotros… R se ocupará de hacer el trabajo sucio de organizar la información una vez importados los datos! 5 Principios básicos Adaptado de (Broman and Woo 2018) Como regla global, columnas (Verticales) son Variables y filas (horizontales) son observaciones (generalmente de unidades experimentales/sujetos individuales) 1 - Consistencia Sean creativos al nombrar las variables: usen 3-4 letras (minúsculas) por palabra y en caso de necesitar usar “_”. No usar acentos ni ñ. Nunca dejen espacios y maximicen el ahorro de letras, siempre y cuando se justifique: severidad = sev incidencia = inc rendimiento = rto hoja = hj (bien podría ser “hoja” también) planta = pl bloque = bq placa = placa temperatura = temp máxima = max En particular prefiero usar el inglés, ya que no tiene acentos ni caracteres especiales. Siempre, siempre, identifiquen hasta el más mínimo detalle de las unidades experimentales (placas, macetas, plantas dentro de las macetas, etc.), al final se recuperará en creces el tiempo extra inicialmente invertido en ello (stand-alone). Adopten siempre los mismos términos No escatimen en columnas: rep_pl -&gt; rep | pl Crear diccionario de términos: Agreguen una planilla con el detalle por extenso de las variables y sus unidades. Piensen que esa planilla la debería entender cualquier persona sin auxilio de sus propios comentarios. 2 - Fechas Fechas si se trata de una fecha específica de un evento en un experimento destinen una columna para ello. Tipo fecha de siembra, fecha de observación de primer sintoma. Si se trata de evaluaciones de una misma unidad experimental en el tiempo será preferible combinar el nombre de variable y la fecha de referencia (comúnmente expresado en dias desde algun punto de referencia). Esto nos permite tener un punto de referencia para la evaluación del momento, corroborando con el último registro: el peso en 45 dias desde emergencia será igual o mayor al dia 30. 3 - Rectangular Todo set de datos tiene sus dimensiones específicas: n fila - n columnas. Si se perdió alguna parcela/planta por algún motivo extra-tratamiento simplemente es un NA, y asi deben definir esa observación, no poner “muerta” o “perdida” 4 - Cero es un dato! Cero no significa ausencia de observación, en este caso podemos usar “NA”, “-”, “.” o dejar en blanco (si se usa .xlsx) En preferencia, llenen todas las celdas, pero siempre un solo dato por celda… 5 - Planilla plana -&gt; DATOS CRUDOS SIN FORMULAS No combinar celdas no resaltar no hacer bordes sin negritas caracteres puros 3.2 Vías de importación Son múltiples las necesidades y vías de importación de datos a nuestro entorno de sesión de R. Principalmente usaremos planillas excel guardados en nuestra computadora. Estos pueden estar guardados en formato .xlsx (planillas tradicionales) o .csv (texto separado con comas, mucho más livianos). Desde nuestra computadora La forma más rápida es vía clicks de mouse en el panel de entorno de la sesión: Import Dataset -&gt; elijen el tipo de archivo que queremos importar, indicamos la ruta de ubicacion del archivo con el botón Browse. En la ventana de importación de datos se generará el codigo (es aconsejable que copien el código generado y lo peguen en el script de la sesión) O bien desde código del script: Archivos excel dat &lt;- readxl::read_excel(&quot;nombre_del_archivo.xls&quot;, ...) # Noten que usamos una función del paquete &quot;readxl&quot;, por lo cual deber ser llamado antes o bien antecediendo el nombre de la función con &quot;::&quot; Importar soja_mancha.xlsx, nombrando “soja” Importar can_phoma.xlsx, nombrando “canola” “can_phoma” es el dataset de un experimento de canola donde fueron testeados 10 fungicidas (mas un control sin protección con fungicida) con 3 bloques en que se registró el progreso de manchas foliares de Phoma lingam a través del tiempo (tiempo termico desde la detcción de la primera mancha). La unidad experimental está identificada en la variable “par” la que contiene la información del bloque (1° dígito), y tratamiento (2°-3° digitos). Archivos de texto .csv dat &lt;- read.csv(&quot;nombre_del_archivo.csv&quot;, header = TRUE, sep = &quot;,&quot;, dec = &quot;.&quot;)# puede variar el simbolo de como se separan las columnas. Siempre chequear el banco de datos importados. dat &lt;- readr::read_csv(&quot;ruta/nombre_del_archivo.csv&quot;) Desde clipboard Muchas veces necesitamos replicar rapidamente un fragmento del dataset desde excel, o bien un vector lo que es posible mediante: dat = read.delim(&quot;clipboard&quot;, dec=&quot;,&quot;) Colección de objetos Muchas veces en una misma sesión se generan nuevos datasets a partir de uno importado. Al reiniciar una sesión deberia tenerse rapidamente disponibles todos los objetos creados en dias previos los que pueden recopilarse en un archivo de múltiples objetos “.RData” e importarse directamente desde este. save(soja, canola, file=&quot;./data/soja_canola.RData&quot;) limpiar memoria y recargar los datos load(&quot;./data/soja_canola.RData&quot;) Crear dataframes tipo SAS (bueno para crear ejemplos reproducibles) dat &lt;- read.table(header=T, text=&#39; Crop x1 x2 x3 x4 Corn 16 27 31 33 Corn 15 23 30 30 Corn 16 27 27 26 Corn 18 20 25 23 Corn 15 15 31 32 Corn 15 32 32 15 Corn 12 15 16 73 Soybean 20 23 23 25 Soybean 24 24 25 32 Soybean 21 25 23 24 Soybean 27 45 24 12 Soybean 12 13 15 42 Soybean 22 32 31 43 &#39;) Exportar datasets write.table(dat, &quot;./data/dat.txt&quot;, sep = &quot;\\t&quot;) Referencias "],
["manip.html", "4 Manipular 4.1 select 4.2 filter 4.3 mutate 4.4 arrange 4.5 summarise 4.6 Dataset “can_phoma”", " 4 Manipular Muchas veces los datos que importamos ya están listos para ser explorados y analizados. Otras veces precisan ser manipulados previamente para ello. En estos casos se parte de un dataset “crudo” y se transforma hacia un dataset “analítico”. Recordando que un dataset debe ser completo con dimensiones n_fila x p_columna, donde: 1- Cada fila debe contener toda la info de la unidad experimental que se está evaluando 2- Cada columna representa una variable (descriptiva o respuesta) 3- Cada celda debe tener su observación (en caso de faltar el dato será un NA) tidyr y dplyr integran parte de la colección de paquetes de tidyverse y facilitan la manipulación de los data frames (Wickham and Grolemund 2016) library(tidyverse) Ambos paquetes utilizan el operador %&gt;% (pipe, tubo en español) lo que proporcionan una mejor interpretación lógica: utiliza el resultado de su lado izquierdo como primer argumento de la función del lado derecho (asemejándose a una receta de torta…) x &lt;- c(1, 2, 3, 4) x %&gt;% sum %&gt;% sqrt Su equivalente de código básico es: sqrt(sum(x)) Importemos los datos “soja” para ver alguno ejemplos. Red de ensayos de fungicidas para el control de mancha anillada en soja load(&quot;./data/soja_canola.RData&quot;) # browseURL(&quot;https://osf.io/jpfet/&quot;) study: identificador arbitrario para cada experimento year: año del experimento location: localidad del experimento cultivar: cultivar de soja utilizado fungic: tratamiento fungicida block: repeticiones sev: severidad (%) evaluada en R6 yield: rendimiento en madurez fisiológica (kg/ha) Los cinco verbos (funciones) principales de dplyr son: select filter mutate arrange summarise Primero vamos a explorar el dataset que acabamos de importar: summary(soja) str(soja) Haremos que las variables tipo caracter sean convertidas a factores: soja &lt;- soja %&gt;% mutate_at(c(&quot;cultivar&quot;, &quot;fungic&quot;,&quot;Yld_level&quot;, &quot;YR_class&quot;, &quot;gr_hab&quot;), funs(as.factor)) summary(soja) str(soja) 4.1 select Vamos a seleccionar las variables: study, year, cultivar, fungic, rep, sev y yield. soja %&gt;% select(study, year, cultivar, fungic, rep, sev, yield) Es posible usar intervalos de varibles con :. Una selección “negativa” de las variables no deseadas daría un mismo resultado: soja %&gt;% select(-Yld_level, -YR_class, -gr_hab, -sev_check) 4.2 filter Semejante a subset. Condiciones separadas por comas equivalen a &amp; de subset. Filtremos la variable fungicida (fungic) por el testigo (ZZ_CHECK) soja %&gt;% select(study:yield) %&gt;% filter(fungic == &#39;ZZ_CHECK&#39;) Ahora, agreguemos el fungicida carbendazim a dosis de 1 litro (CZM[1]) al dataset soja %&gt;% select(study:yield) %&gt;% filter(fungic %in% c(&quot;ZZ_CHECK&quot;,&quot;CZM[1]&quot;)) 4.3 mutate Creación de nuevas variables (a partir de las existentes) Muchas variables biológicas no cumplen con los supuestos de las pruebas estadísticas paramétricas: no se distribuyen normalmente, las desviaciones estándar no son homogéneas, o ambas. Hay extensa bibliografia al respecto, recomendando cual transformación es la más adecuada para cada tipo de variable y asi poder ser analizada por un ANOVA tradicional (paramétrico). Como fitopatólogos, la no normalidad es lo predominante. El caso mas común es la severidad de enfermedades que comparamos a través de diferentes tratamientos (cultivar, fungicida, practica de manejo, etc.) Dos transformaciones son mayormente sugeridas para la severidad: Transformacion Arcsine:consiste en tomar el arcoseno de la raiz cuadrada de un numero. Transformación logit: soja1 &lt;- soja %&gt;% select(study:yield) %&gt;% filter(fungic %in% c(&quot;ZZ_CHECK&quot;,&quot;CZM[1]&quot;)) %&gt;% mutate(sev_arc = asin(sqrt(sev/100)), sev_logit = car::logit(sev, percents=TRUE),# log(sev/100/(1-sev/100)), # yield_tn = yield/1000) # browseURL(&quot;http://strata.uga.edu/8370/rtips/proportions.html&quot;) soja &lt;- readr::read_csv(&quot;data/soja_mancha.csv&quot;) soja &lt;- soja %&gt;% mutate_if(is.character, as.factor) 4.4 arrange Ordena crecientemente de acuerdo a la columna que le indiquemos. Utilizar desc para orden decrescente. soja1 %&gt;% arrange(year, cultivar) soja1 %&gt;% arrange(year, desc(cultivar)) 4.5 summarise Generalmente acompañada de la función group_by la cual permite aplicar un cálculo a las observaciones agrupando por niveles de algún factor (equivale a una tabla dinámica de excel) Veamos cuanto fue el rendimiento promedio y el desvio standard para cada fungicida a través de todos los ensayos: soja %&gt;% group_by(fungic) %&gt;% summarise(yield_mean = mean(yield), yield_sd = sd(yield)) Calculen el rendimiento mínimo y máximo por fungicida Algunas funciones interesantes para la descripción del dataset: n(), n_distinct(). Cuantos ensayos fueron realizados por año: soja %&gt;% group_by(year) %&gt;% summarize(n = n_distinct(study)) Cuantas parcelas tenia cada ensayo: soja %&gt;% group_by(study, year, cultivar) %&gt;% summarize(plots = n()) Adicione una columna de potencial de rendimento del ensayo (rend_pot), considerando el máximo rendimiento observado en ese ensayo. Usando la función ifelse cree una nueva variable categórica “presión de enfermedad” considerando a “sev_check”: Low o High by_check = soja %&gt;% filter(fungic==&quot;ZZ_CHECK&quot;) %&gt;% group_by(study) %&gt;% summarize(sev_check = round(mean(sev, na.rm = TRUE),1)) %&gt;% mutate(Dis_level = ifelse(sev_check &lt; 30, &quot;Low&quot;, &quot;High&quot;)) Funciones auxiliares join junta dos data.frames a través de puntos en común. Por ejemplo, si queremos unir las variables “sev_check” y “Dis_level” al dataset soja: soja %&gt;% full_join(by_check, by=&quot;study&quot;) 4.6 Dataset “can_phoma” can_phoma Esto seria uma forma “wide” de representación del dataset (crudo). Para analizar el efecto del tratemiento fungicida necesitamos calcular el área bajo la curva (AUC) del progreso de la enfermedad. Para esto vamos a transponer can_phoma al formato “long”. La función gather (del inglés “reunir”, paquete tidyr) apila las columnas que indiquemos. # crearemos una variable &quot;tt&quot; con los nombres de las columnas con números, # y otra &quot;incp&quot; (incidencia en proporción) con los valores correspondientes. can_long &lt;- can_phoma %&gt;% gather(`015`, `058`, `095`, `146.0`, `165.0`, `180.0`, `248.0`, key = &quot;tt&quot;, value = &quot;incp&quot;) # gather(tt, incp, -c(par:bk)) ;) # save(can_phoma, can_long, file = &quot;canolass.RData&quot;) can_long # Precisamos que tt sea clase &quot;numérica&quot; para ciertos cálculos can_long &lt;- can_long %&gt;% mutate_at(c(&quot;trt&quot;,&quot;bk&quot;), funs(as.factor)) %&gt;% mutate_at(c(&quot;tt&quot;, &quot;inc&quot;), funs(as.numeric)) # can_long$tt &lt;- as.numeric(can_long$tt) Calcularemos un valor de AUC por parcela con auxilio de las funciones group_by y summarize # if(require(MESS)) {install.packages(&quot;MESS&quot;)} auc &lt;- can_long %&gt;% group_by(trt, bk) %&gt;% summarize(AUC = MESS::auc(inc, tt)) ggplot(auc, aes(x=trt, y=AUC))+ geom_boxplot() Ahora si, can_phoma está listo para entrar al próximo paso: modelado. Referencias "],
["explore.html", "5 Visualizar 5.1 Mancha anillada en soja 5.2 Phoma en colza 5.3 Fertilización con N y S en sorgo", " 5 Visualizar library(tidyverse) Una vez que nuestros datos han sido importados y manipulados podríamos comenzar la exploración numérica y visual de los mismos. La visualización de datos es parte fundamental del flujo de trabajo de un análisis de datos, tanto para explorar los datos, como para explicar / comunicar los resultados. Es decir, dominar las herramientas de visualización resulta imprescindible para un científico cuya materia prima son los datos. Los gráficos exploratorios requieren una mínima elaboración, la suficiente para entenderlos y detectar datos anormales (probablemente por error de digitación o outliers). El paquete ggplot2 se puede utilizar tanto para la creación rápida de gráficos como para gráficos complejos y detallados (con fines de publicaciones científicas). Tiene una gramática propia y la idea original es que un gráfico puede ser elaborado a partir de la combinación de capas, pudiendo tener estas diferentes bases de datos y objetos gráficos (puntos, líneas, barras, etc). Un mismo dataset puede ser visualizado de múltiples formas, partiendo de la simple visualización de las observaciones con alguna medida de posición como ser la media o mediana. Cuando las observaciones son 5 o más es común acompanãr la media de posición (media o mediana) por alguna medida de dispersión: desvio estándar, error estándar o intervalo de confianza de la media (95% IC). A continuación se presentan algunas opciones de gráficos que surgen de diferentes combinaciones de medidas de posición y de dispersión. 5.1 Mancha anillada en soja url1 &lt;- &quot;https://raw.githubusercontent.com/juanchiem/R_Intro/master/data/soja_mancha.csv&quot; soja &lt;- read.csv(textConnection(RCurl::getURL(url1))) Nos quedaremos solo con dos cultivares: “BMX_Potencia_RR” y “M9144_RR” (nos aseguraremos que no queden ningun otro nivel del factor cultivar) soja1 &lt;- soja %&gt;% filter(cultivar %in% c(&quot;BMX_Potencia_RR&quot;, &quot;M9144_RR&quot;)) %&gt;% droplevels()# necesario para remover los cultivares no seleccionados Exploración del dataset ftable(xtabs(~ study + cultivar, soja)) Estableceremos quien es el dataset a ser graficado y quienes son las variables en los ejes x e y: p0 = ggplot(soja, aes(x=sev, y=yield)) p0 Agregaremos las observaciones p0 + geom_point() Identificaremos a que cultivar corresponden las observaciones y agregaremos una línea de tendencia general para cada cultivar: p0 + geom_point(aes(color = cultivar)) + geom_smooth(method=&quot;lm&quot;, aes(color = cultivar)) Qué pueden concluir al respecto? Ahora dividiremos a cada cultivar en paneles individuales e identificaremos las tendencias intra-estudio. p0 + geom_point(alpha=0.2)+ geom_smooth(method=&quot;lm&quot;, aes(group = study))+ facet_wrap(~cultivar)+ labs(x=&quot;Disease severity (%)&quot;, y = &quot;Yield (kg/ha)&quot;) + theme_bw() Cambiaron los resultados? que puede concluir ahora? Exploremos el experimento 1 soja_exp1 &lt;- soja %&gt;% filter(study == 1) %&gt;% droplevels()# necesario para remover los cultivares no seleccionados # library(Rmisc) # summarySE(soja_exp1, measurevar=&quot;yield&quot;, groupvars=&quot;fungic&quot;) ggplot(soja_exp1, aes(x=fungic, y=yield)) + # geom_boxplot()+ # Observaciones reales ----- geom_point(alpha=0.2)+ # aes(color=factor(rep) # geom_jitter(width = 0.1) # Medida de posición ----- stat_summary(fun.y=&quot;mean&quot;, geom=&quot;point&quot;, size=2)+ # stat_summary(fun.y=&quot;mean&quot;, geom=&quot;bar&quot;) # Medida de dispersión ----- stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;)+ stat_summary(fun.data= mean_sdl, geom = &quot;errorbar&quot;, color=&quot;red&quot;)+ stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, color=&quot;blue&quot;) Afinando la apariencia para paper levels(soja_exp1$fungic) library(forcats) soja_exp1 %&gt;% mutate(fungic = fct_recode(fungic, `Czm` = &quot;CZM[1]&quot;, `Czm+CM+Tebu` =&quot;CZM_CM_TEBU[1]&quot;, `Czm+LS` = &quot;CZM+LS[1+0.5]&quot;, `Epo+Flux+Pyra (0.8L)` = &quot;EPO_FLUX_PYRA[0.8]&quot;, `Epo+Flux+Pyra (1L)` =&quot;EPO_FLUX_PYRA[1]&quot;, `Fluo` = &quot;FLUO[0.4]&quot;, `Prot+Trif` = &quot;PROT_TRIF[0.4]&quot;, `Tiof` = &quot;TIOF[1]&quot;, `Check` = &quot;ZZ_CHECK&quot;), fungic1 = fct_relevel(fungic, &quot;Check&quot;, &quot;Czm&quot;, &quot;Czm+CM+Tebu&quot;, &quot;Czm+LS&quot;, &quot;Epo+Flux+Pyra (0.8L)&quot;, &quot;Epo+Flux+Pyra (1L)&quot;, &quot;Fluo&quot;, &quot;Prot+Trif&quot;, &quot;Tiof&quot;)) %&gt;% ggplot(aes(x = fungic1, y = yield)) + geom_boxplot(fill=&quot;grey80&quot;)+ # Agregamos detalles esteticos theme_bw()+ labs(x=&quot;Fungicide treatment&quot;, y=&quot;Soybean yield (kg/ha)&quot;)+ theme(axis.text.x = element_text(angle=60, vjust=1, hjust = 1, size=8)) # ggsave(w=80, h=80, units=&quot;mm&quot;, dpi=150, scale = 1, # &quot;WORKING_DIRECTORY/plots/plot_1.tiff&quot;) 5.2 Phoma en colza “can_phoma” es el dataset de un experimento de colza (Brassica napus) donde fueron testeados 10 fungicidas (mas un control sin protección con fungicida) con 3 bloques en que se registró el progreso de manchas foliares de Phoma lingam a través del tiempo (tiempo térmico desde la detección de la primera mancha). La unidad experimental está identificada en la variable “par” la que contiene la información del bloque (1° dígito), y tratamiento (2°-3° digitos). 1 - Importación de datos (desde internet - googlesheets) library(gsheet) url1=&quot;https://docs.google.com/spreadsheets/d/135CDYxoU9KF-Gl32461EWpX0LlXbsSGZ4t_i-0VPpko/edit?usp=sharing&quot; # browseURL(url1) can_phoma = gsheet2tbl(url1) can_phoma # str(can_phoma) Esto seria uma forma “wide” de representación del dataset (crudo). Para analizar el efecto del tratamiento fungicida necesitamos calcular el área bajo la curva (AUC) del progreso de la enfermedad. Para esto vamos a transponer can_phoma al formato “long”. La función gather (del inglés “reunir”, paquete tidyr) apila las columnas que indiquemos. 2 - Manipulación + transformación Crearemos una variable “tt” con los nombres de las columnas con números, y otra “inc” (incidencia) con los valores correspondientes: can_long &lt;- can_phoma %&gt;% gather(`015`, `058`, `095`, `146`, `165`, `180`, `248`, key = &quot;tt&quot;, value = &quot;inc&quot;) can_long # str(can_long) Precisamos que tt sea clase “numérica” para ciertos cálculos can_long$tt &lt;- as.numeric(can_long$tt) # can_long$tt can_long &lt;- can_long %&gt;% arrange(plot) str(can_long) Exploramos las evaluaciones originales con gráfico de puntos + líneas individualizando cada parcela en un panel. ggplot(can_long, aes(x=tt, y=inc)) + geom_point() + geom_line(aes(group=plot)) + facet_grid(bk~trt) Verificamos la presencia de errores de tipeo en dos parcelas: 202 y 310. (editamos el dataset original) # editar los datos: can_long&lt;- edit(can_long) Calculamos un valor de AUC por parcela con auxilio de las funciones group_by + summarize y agricolae::audpc # Funcion na.omit can_auc &lt;- na.omit(can_long) %&gt;% group_by(trt, bk, sev_cank) %&gt;% summarise(auc_i = agricolae::audpc (inc, tt)) can_auc Exploramos la variable transformada auc_p con boxplot ggplot(can_auc, aes(x=factor(trt), y=auc_i)) + geom_boxplot() Exploramos la variable original sev_cank con boxplot ggplot(can_auc, aes(x=factor(trt), y=sev_cank)) + geom_boxplot() Ahora si, can_phoma está listo para entrar al próximo paso: modelado. 5.3 Fertilización con N y S en sorgo sorg &lt;- readr::read_csv(&quot;~/GitHub/R_Intro/data/sorgo.csv&quot;) Exploracion de todas las variables # xtabs(~ ferti + cond + dias, long) pd = position_dodge(width = 0.5) long %&gt;% drop_na(valor) %&gt;% ggplot(aes(x=factor(hibr), y=valor, group=trt, color=factor(trt))) + geom_jitter(alpha=0.5, size=0.8, width=0.2)+ stat_summary(aes(group=trt), fun.data = mean_cl_boot, size = 0.05, position=pd) + stat_summary(aes(group=trt), size = 2, fun.y=&quot;mean&quot;, geom=&quot;point&quot;, position=pd, show.legend = FALSE)+ facet_wrap(variable ~ ph, scales = &quot;free&quot;) # ggsave(filename = &quot;exp3.png&quot;, # path = &quot;C:/Users/edwardsmolina.juan/Dropbox/Papers/1 In progress/sorgo_belen/plots&quot;) library(GGally) # sorg[,5:11] ggpairs(sorg, columns = 5:11, ggplot2::aes(colour=ph), columnLabels = c(&quot;Altura&quot;, &quot;Peso seco&quot;, &quot;Fosforo total&quot;, &quot;Zinc&quot;, &quot;Nitrogeno&quot;, &quot;Hierro&quot;, &quot;Spad&quot;)) "],
["model.html", "6 Modelar", " 6 Modelar (En construcción, mientras seguir codigos en clases) Se incluirá: Modelos lineares - diagnosticos library(broom) "],
["ref.html", "7 Referencias", " 7 Referencias "]
]
